{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaso129/2023dlAssignments/blob/main/Text_Sentiment_Classification_with_Prompt_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Z1Snuk7rIK"
      },
      "source": [
        "# MIS 583 Assignment 6: Text Sentiment Classification with Prompt Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSwr9MgZogRZ"
      },
      "source": [
        "Before we start, please put your name and SID in following format: <br>\n",
        ": LASTNAME Firstname, ?00000000   //   e.g.) 李晨愷, M114020035"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DzsjuDhlz_k"
      },
      "source": [
        "**Your Answer:**   \n",
        "Hi I'm 劉捷生, M124020043"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d-Zzebq7rIM"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc9gd_Wk7rIN"
      },
      "source": [
        "**Sentiment Classification** is an automated process of identifying opinions in text and labeling them as positive or negative based on the emotions customers express within them.\n",
        "\n",
        "In Task 1, you need to fine-tune a pre-trained language model (e.g., BERT) to predict the sentiment of given tweets.\n",
        "\n",
        "In Task 2, we employ prompts to enable the model to perform sentiment analysis through in-context learning, eliminating the need for additional training.\n",
        "\n",
        "In Task 3, you will use the method called LM-BFF to utilize the model in generating the optimal template and verbalizer autonomously.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhqXL5HZP3MN"
      },
      "source": [
        "# Notice\n",
        "**You are not allow to use the model like GPT family or pre-trained weight using SST-2 and twitter dataset!!!!!!!!!!!!!!!!!**\n",
        "\n",
        "You can use BERT and RoBERTa encoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giUId1Naqacs"
      },
      "source": [
        "##  Versions of used packages\n",
        "\n",
        "We will check PyTorch version to make sure everything work properly.  \n",
        "We use `python==3.7.14`, `torch==1.12.1+cu113` and `torchvision==0.13.1+cu113`.  \n",
        "This is the default version in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vuw-gNvjqcYe",
        "outputId": "88097baa-a189-40dc-9da2-822c1ec2d493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "torch 2.1.0+cu121\n",
            "torchvision 0.16.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torchvision\n",
        "print('python', sys.version.split('\\n')[0])\n",
        "print('torch', torch.__version__)\n",
        "print('torchvision', torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCdBfvgSP3MO"
      },
      "source": [
        "# Task 1: Text Sentiment Classification (40 points)\n",
        "\n",
        "In this task, you need to fine-tune a pre-trained language model (e.g., BERT or RoBERTa encoder) to predict the sentiment of given tweets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a4s_a5D7rIR"
      },
      "source": [
        "## Loading Model and Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPUkTbnL7rIR"
      },
      "source": [
        "First, let's talk about the model. The Hugging Face team has created an amazing framework called \"transformers\" for NLP tasks. It includes many state-of-the-art machine learning models for PyTorch, TensorFlow, and JAX.\n",
        "\n",
        "To start with this package, follow [this link to installation and a basic tutorial](https://pytorch.org/hub/huggingface_pytorch-transformers/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rK0ouXa09pDU",
        "outputId": "b5f460ce-e4bc-482e-8c18-808bdb5eddb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy installation\n",
            "pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (1.60.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.17.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.5.1)\n",
            "Collecting protobuf==3.9.2\n",
            "  Downloading protobuf-3.9.2-py2.py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from protobuf==3.9.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from protobuf==3.9.2) (1.16.0)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.4.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-aiplatform 1.38.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-bigquery 3.12.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.24.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-iam 2.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-resource-manager 1.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "googleapis-common-protos 1.62.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.9.2 which is incompatible.\n",
            "grpcio-status 1.48.2 requires protobuf>=3.12.0, but you have protobuf 3.9.2 which is incompatible.\n",
            "proto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 3.9.2 which is incompatible.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 3.9.2 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.9.2 which is incompatible.\n",
            "tensorflow-datasets 4.9.3 requires protobuf>=3.20, but you have protobuf 3.9.2 which is incompatible.\n",
            "tensorflow-hub 0.15.0 requires protobuf>=3.19.6, but you have protobuf 3.9.2 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyprind\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: pyprind\n",
            "Successfully installed pyprind-2.11.3\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.34.4-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.4 (from boto3)\n",
            "  Downloading botocore-1.34.4-py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.10.0,>=0.9.0 (from boto3)\n",
            "  Downloading s3transfer-0.9.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.4->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.4->boto3) (1.16.0)\n",
            "Installing collected packages: sentencepiece, sacremoses, jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.34.4 botocore-1.34.4 jmespath-1.0.1 s3transfer-0.9.0 sacremoses-0.1.1 sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "# you might need some additional installations there\n",
        "!echo happy installation\n",
        "!pip -V\n",
        "!pip install grpcio\n",
        "!pip install google-auth\n",
        "!pip install protobuf==3.9.2\n",
        "!pip install pyprind\n",
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmGCAevi7rIS",
        "outputId": "442b36e4-4a83-4b8e-b268-0af5fff0d084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_transformers_main\n",
            "Using cache found in /root/.cache/torch/hub/huggingface_transformers_main\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "\n",
        "#########################################################################\n",
        "#            Loading tokenizer and model from transformer               #\n",
        "#########################################################################\n",
        "# from transformers import xxx\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "distilbert_type = 'distilbert-base-uncased'\n",
        "\n",
        "# ---------- 1. load from torch.hub ----------\n",
        "tokenizer = torch.hub.load('huggingface/transformers', 'tokenizer', distilbert_type)\n",
        "model = torch.hub.load('huggingface/transformers', 'model', distilbert_type)\n",
        "\n",
        "# ---------- 2. load from installed huggingface ----------\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(distilbert_type)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(distilbert_type)\n",
        "\n",
        "\n",
        "\n",
        "# finetune from the output from bert to your task\n",
        "model.classifier = nn.Linear(768, 3, bias=True)\n",
        "#########################################################################\n",
        "#                          End of your code                             #\n",
        "#########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiMThsYeDa2O"
      },
      "source": [
        "## How to Get Data\n",
        "\n",
        "Please open the file `twitter_sentiment.zip`, creat shortcut to your Google Drive.\n",
        "\n",
        "1. open [LINK of Google Drive](https://drive.google.com/file/d/19Ty2lVAm55VL5QIM-MMQhhOzWXeMtxeV/view?usp=sharing)\n",
        "2. Click \"Add shortcut to Drive\" in the top-right corner.\n",
        "3. Select the location where you want to place the shortcut.\n",
        "4. Click Add shortcut.\n",
        "\n",
        "After above procedures, we have a shortcut of zip file of dataset.  \n",
        "We can access this in colab after granting the permission of Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "請先到共用雲端硬碟將檔案 `twitter_sentiment.zip`，建立捷徑到自己的雲端硬碟中。\n",
        "\n",
        "> 操作步驟\n",
        "1. 點開雲端[連結](https://drive.google.com/file/d/19Ty2lVAm55VL5QIM-MMQhhOzWXeMtxeV/view?usp=sharing)\n",
        "2. 點選右上角「新增雲端硬碟捷徑」\n",
        "3. 點選「我的雲端硬碟」\n",
        "4. 點選「新增捷徑」\n",
        "\n",
        "完成以上流程會在你的雲端硬碟中建立一個檔案的捷徑，接著我們在colab中取得權限即可使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZnFgi5i_2oA",
        "outputId": "425ce7f1-cb42-4316-a3ca-9476ea92db36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqO8DiB6VRQZ"
      },
      "source": [
        "## Unzip Data\n",
        "\n",
        "解壓縮 `twitter_sentiment.zip` 後可以發現裡面有三個csv檔。\n",
        "\n",
        "- `train.csv`, `test.csv` and `val.csv`\n",
        "\n",
        "Training set 有 **10248** 筆資料.  \n",
        "Validation set 有 **1317** 筆資料.  \n",
        "Testing set 有 **3075** 筆資料.  \n",
        "\n",
        "注意: 若有另外設定存放在雲端硬碟中的路徑，請記得本處路徑也須做更動。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSlTMdxf8Zd7"
      },
      "outputs": [],
      "source": [
        "!unzip -qq ./drive/MyDrive/twitter_sentiment.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Uu2DS91P3MR"
      },
      "source": [
        "# Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf5GXTme7rIT"
      },
      "outputs": [],
      "source": [
        "# Utility function to extract text and label from csv file\n",
        "def get_texts(f_name='./drive/MyDrive', mode='train'):\n",
        "    text_list = []\n",
        "    label_list = []\n",
        "\n",
        "    f_path = os.path.join(f_name, '{}.csv'.format(mode))\n",
        "    with open(f_path) as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for line in reader:\n",
        "            text_list.append(line['text'])\n",
        "            if mode != 'test':\n",
        "                label_list.append(int(line['sentiment_label']))\n",
        "\n",
        "    return text_list, label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fpY0ZrK7rIV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class TwitterDataset(Dataset):\n",
        "    def __init__(self, f_name='./drive/MyDrive', mode='train'):\n",
        "        self.mode = mode\n",
        "\n",
        "        text_list, label_list = get_texts(f_name, mode)\n",
        "        print('mode', mode, 'has', len(text_list), 'datas')\n",
        "        text_list = tokenizer(text_list,\n",
        "                             truncation=True, padding=True,\n",
        "                             return_tensors='pt')\n",
        "\n",
        "        self.text_list = text_list['input_ids']\n",
        "        self.mask_list = text_list['attention_mask']\n",
        "\n",
        "        self.label_list = label_list\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.text_list[idx]\n",
        "        mask = self.mask_list[idx]\n",
        "        if self.mode == 'test':\n",
        "            return text, mask\n",
        "        label = torch.tensor(self.label_list[idx])\n",
        "        return text, mask, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fW-r69uP3MS"
      },
      "source": [
        "## `DataLoader`\n",
        "\n",
        "`torch.utils.data.DataLoader` define how to sample from `dataset` and some other function like:\n",
        "+ `shuffle` : set to `True` to have the data reshuffled at every epoch\n",
        "+ `batch_size` : how many samples per batch to load\n",
        "\n",
        "See [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for more details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCmM4FSw7rIW",
        "outputId": "6be37a2a-d11b-4418-e8ae-d3c84fed3e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mode train has 10248 datas\n",
            "mode val has 1317 datas\n",
            "mode test has 3075 datas\n"
          ]
        }
      ],
      "source": [
        "dataset_train = TwitterDataset(mode='train')\n",
        "dataset_val = TwitterDataset(mode='val')\n",
        "dataset_test = TwitterDataset(mode='test')\n",
        "\n",
        "batch_size = 64\n",
        "train_data = DataLoader(dataset_train, batch_size=batch_size,\n",
        "                       shuffle=True)\n",
        "val_data = DataLoader(dataset_val, batch_size=batch_size // 2,\n",
        "                       shuffle=False)\n",
        "test_data = DataLoader(dataset_test, batch_size=batch_size // 2,\n",
        "                       shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqkvofHc7rIY",
        "outputId": "33d695d0-6e8d-4732-e50c-e898c7ac3b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token ['[CLS]', '@', 'united', 'i', 'have', 'never', 'been', 'mis', '##lea', '##d', 'by', 'a', 'company', 'as', 'many', 'times', 'as', 'i', 'have', 'this', 'week', 'by', 'united', 'airlines', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "token to s [CLS] @ united i have never been mislead by a company as many times as i have this week by united airlines ! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ],
      "source": [
        "t = tokenizer.convert_ids_to_tokens(dataset_train[0][0]) # converts a sequence of numeric IDs in the training dataset into their corresponding tokens using the specified tokenizer.\n",
        "print('token', t)\n",
        "print('token to s', tokenizer.convert_tokens_to_string(t)) # converts a sequence of tokens (t) back into the original text string using the specified tokenizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCr-TzPlP3MS"
      },
      "source": [
        "# Define loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxZrfCqW7rIY"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "from torch import nn\n",
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpwgE2Gd7rIZ"
      },
      "source": [
        "# Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlaiAZAD7rIa"
      },
      "outputs": [],
      "source": [
        "def accuracy(raw_preds, y):\n",
        "    preds = raw_preds.argmax(dim=1)\n",
        "    acc = (preds == y).sum()\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzzRpCOKP3MT"
      },
      "source": [
        "# Train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmc_Gms97rIa"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    total = 0\n",
        "    for text, mask, label in tqdm(data, total=len(data)):\n",
        "        text = text.to(device)\n",
        "        mask = mask.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        #########################################################################\n",
        "        #                          Testing process                              #\n",
        "        #########################################################################\n",
        "        # 1. Clean the gradients of optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # 2. Put correct variables into model\n",
        "        outputs = model(input_ids=text, attention_mask=mask)\n",
        "        # 3. Get prediction\n",
        "        predictions = torch.argmax(outputs.logits, dim=1)\n",
        "        # 4. Evalutate by criterion and accuracy\n",
        "        loss = criterion(outputs.logits, label)\n",
        "        acc = (predictions == label).sum()\n",
        "        #########################################################################\n",
        "        #                          End of your code                             #\n",
        "        #########################################################################\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        train_loss_list.append(loss.item())\n",
        "        epoch_acc += acc.item()\n",
        "        total += len(text)\n",
        "    return epoch_loss / total, epoch_acc / total\n",
        "\n",
        "def test(model, data, criterion, log_loss=False):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    total = 0\n",
        "    for text, mask, label in tqdm(data, total=len(data)):\n",
        "        text = text.to(device)\n",
        "        mask = mask.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        #########################################################################\n",
        "        #                          Training process                             #\n",
        "        #########################################################################\n",
        "        # 1. Put correct variables into model\n",
        "        outputs = model(input_ids=text, attention_mask=mask)\n",
        "        # 2. Get prediction\n",
        "        predictions = torch.argmax(outputs.logits, dim=1)\n",
        "        # 3. Evalutate by criterion and accuracy\n",
        "        loss = criterion(outputs.logits, label)\n",
        "        acc = (predictions == label).sum()\n",
        "        #########################################################################\n",
        "        #                          End of your code                             #\n",
        "        #########################################################################\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        if log_loss:\n",
        "            val_loss_list.append(loss.item())\n",
        "        epoch_acc += acc.item()\n",
        "        total += len(text)\n",
        "    return epoch_loss / total, epoch_acc / total\n",
        "\n",
        "# class for monitoring train and test acc/loss\n",
        "class Meter:\n",
        "    def __init__(self):\n",
        "        self.train_loss_list = []\n",
        "        self.train_acc_list = []\n",
        "        self.val_loss_list = []\n",
        "        self.val_acc_list = []\n",
        "\n",
        "    def update(self, train_loss, train_acc, val_loss, val_acc):\n",
        "        self.train_loss_list.append(train_loss)\n",
        "        self.train_acc_list.append(train_acc)\n",
        "        self.val_loss_list.append(val_loss)\n",
        "        self.val_acc_list.append(val_acc)\n",
        "\n",
        "    def plot(self):\n",
        "        x = range(len(self.train_loss_list))\n",
        "        plt.plot(x, self.train_loss_list)\n",
        "        plt.plot(x, self.val_loss_list, color='r')\n",
        "        plt.legend(['train_loss', 'val_loss'])\n",
        "        plt.show()\n",
        "        plt.plot(x, self.train_acc_list)\n",
        "        plt.plot(x, self.val_acc_list, color='r')\n",
        "        plt.legend(['train_acc', 'val_acc'])\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExZyrKd57rIb"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVDe-fRe7rIc",
        "outputId": "bf72c3cb-37a4-4a75-f20d-910478e1f6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161/161 [00:59<00:00,  2.69it/s]\n",
            "100%|██████████| 42/42 [00:02<00:00, 16.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train_loss: 0.009573340096062371 train_acc: 0.7439500390320063\n",
            "Epoch 1 val_loss:  0.013883067573574156 val_acc : 0.8253606681852695\n",
            "---------- e 1 save best model ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161/161 [00:59<00:00,  2.72it/s]\n",
            "100%|██████████| 42/42 [00:02<00:00, 15.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train_loss: 0.0059992062447012445 train_acc: 0.8512880562060889\n",
            "Epoch 2 val_loss:  0.01278517916855164 val_acc : 0.8488990129081245\n",
            "---------- e 2 save best model ----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161/161 [00:59<00:00,  2.72it/s]\n",
            "100%|██████████| 42/42 [00:02<00:00, 14.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train_loss: 0.004547666936420678 train_acc: 0.8935402029664324\n",
            "Epoch 3 val_loss:  0.013520792765923315 val_acc : 0.8382687927107062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161/161 [00:59<00:00,  2.71it/s]\n",
            "100%|██████████| 42/42 [00:02<00:00, 15.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train_loss: 0.003265931501120887 train_acc: 0.9292544886807181\n",
            "Epoch 4 val_loss:  0.01576608467504846 val_acc : 0.829916476841306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 161/161 [00:59<00:00,  2.72it/s]\n",
            "100%|██████████| 42/42 [00:02<00:00, 15.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train_loss: 0.002177115956904435 train_acc: 0.9546252927400468\n",
            "Epoch 5 val_loss:  0.018144545880066417 val_acc : 0.8253606681852695\n"
          ]
        }
      ],
      "source": [
        "#########################################################################\n",
        "#                          Hyper-parameters                             #\n",
        "#########################################################################\n",
        "max_epoch = 5\n",
        "log_interval = 1\n",
        "best_acc = 0\n",
        "#########################################################################\n",
        "#                          End of your code                             #\n",
        "#########################################################################\n",
        "\n",
        "m = Meter()\n",
        "\n",
        "for epoch in range(1, max_epoch + 1):\n",
        "    train_loss, train_acc = train(model, train_data, optimizer, criterion)\n",
        "    val_loss, val_acc = test(model, val_data, criterion, log_loss=True)\n",
        "\n",
        "    if epoch % log_interval == 0:\n",
        "        print('Epoch {} train_loss: {} train_acc: {}'.format(\n",
        "            epoch, train_loss, train_acc\n",
        "        ))\n",
        "        print('Epoch {} val_loss:  {} val_acc : {}'.format(\n",
        "            epoch, val_loss, val_acc\n",
        "        ))\n",
        "\n",
        "    m.update(train_loss, train_acc, val_loss, val_acc)\n",
        "\n",
        "    # model checkpoint\n",
        "    torch.save(model.state_dict(), 'drive/MyDrive/ckpts/e{}.pt'.format(epoch))\n",
        "    if val_acc > best_acc:\n",
        "        best_model = model\n",
        "        best_acc = val_acc\n",
        "        print('-'*10, 'e', epoch, 'save best model', '-'*10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "SmtW58OR7rIc",
        "outputId": "3708f2af-9db3-43c6-e439-fd1d96811127"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPu0lEQVR4nO3deVwU9f8H8Nfuwi43iNyI3GCioHnw9dakTA2P0swuNbXs+mV8zTRv+yqZfRUr+9q3b3Z/v2XepWmCR3kX3qgIioLceHAKC7vz+2NiFeVaBGaP1/PxmAcyOzO8x3HdF/P+zIxMEAQBRERERAZMLnUBRERERA1hYCEiIiKDx8BCREREBo+BhYiIiAweAwsREREZPAYWIiIiMngMLERERGTwGFiIiIjI4FlIXUBz0Gq1yMrKgr29PWQymdTlEBERUSMIgoDi4mJ4eXlBLq//HIpJBJasrCz4+PhIXQYRERE1QUZGBtq1a1fvMiYRWOzt7QGIO+zg4CBxNURERNQYRUVF8PHx0X2O18ckAkt1G8jBwYGBhYiIyMg0ZjgHB90SERGRwWNgISIiIoPHwEJEREQGzyTGsDSGIAioqqqCRqORuhTSk0KhgIWFBS9ZJyIyY2YRWNRqNbKzs1FWViZ1KdRENjY28PT0hFKplLoUIiKSgMkHFq1Wi7S0NCgUCnh5eUGpVPI3dSMiCALUajXy8/ORlpaG4ODgBm8uREREpsfkA4tarYZWq4WPjw9sbGykLoeawNraGpaWlrhy5QrUajWsrKykLomIiFqZ2fyqyt/KjRuPHxGReeOnABERERk8BhYiIiIyeAwsZsLPzw9xcXFSl0FERNQkJj/o1pgNHDgQXbp0aZag8ccff8DW1vb+iyIiIpIAA4sREwQBGo0GFhYNH0ZXV9dWqIiIiExNxvUybDmRiZtllZj7WEfJ6jDLlpAgCChTV0kyCYLQqBonTpyIffv2YdWqVZDJZJDJZPjyyy8hk8nwyy+/oFu3blCpVNi/fz8uXryIkSNHwt3dHXZ2dujRowfi4+NrbO/ulpBMJsN//vMfjB49GjY2NggODsbWrVsbVZtGo8HkyZPh7+8Pa2trhIaGYtWqVfcst3btWoSFhUGlUsHT0xOvvfaa7rWbN2/ipZdegru7O6ysrNCpUyf8/PPPjfr5RETUsm6WqfHdkSsYu+Yg+r2/Bx/8egFfH7qCm2VqyWoyyzMstyo16Dh/pyQ/++ziIbBRNvzXvmrVKly4cAGdOnXC4sWLAQBJSUkAgFmzZuGDDz5AQEAA2rRpg4yMDAwbNgxLliyBSqXC119/jejoaCQnJ6N9+/Z1/oxFixbh/fffx/Lly/HRRx/hmWeewZUrV+Ds7FxvbVqtFu3atcOPP/6Itm3b4uDBg3jxxRfh6emJJ598EgDwr3/9CzExMXjvvfcwdOhQFBYW4sCBA7r1hw4diuLiYnz77bcIDAzE2bNnoVAoGvV3SEREza+8UoM95/Ow6Xgm9iTnoVIj/oItkwG9A9tiVBdvqCyk+3/aLAOLMXB0dIRSqYSNjQ08PDwAAOfPnwcALF68GA8//LBuWWdnZ0REROi+f/fdd7Fp0yZs3bq1xlmNu02cOBHjx48HACxduhQffvghjh49ikcffbTe2iwtLbFo0SLd9/7+/jh06BDWrVunCyz/+Mc/8Pe//x1vvPGGbrkePXoAAOLj43H06FGcO3cOISEhAICAgICG/1KIiKhZabUCjqRdx+bjmdh+JhvF5VW61x7wdMDorl4YEeEND0fpb9hploHF2lKBs4uHSPaz71f37t1rfF9SUoKFCxdi27ZtyM7ORlVVFW7duoX09PR6txMeHq77s62tLRwcHJCXl9eoGlavXo21a9ciPT0dt27dglqtRpcuXQAAeXl5yMrKwuDBg2td98SJE2jXrp0urBARUetKzinGpuOZ2HoiE1mF5br5Xo5WGNnVG6O6eCPUw17CCu/VpMCyevVqLF++HDk5OYiIiMBHH32Enj171rpsZWUlYmNj8dVXXyEzMxOhoaFYtmxZjd/iFy5cWOM3dgAIDQ3VnVFobjKZrFFtGUN199U+M2bMwK5du/DBBx8gKCgI1tbWGDNmDNTq+nuNlpaWNb6XyWTQarUN/vzvv/8eM2bMwD//+U/06tUL9vb2WL58OY4cOQJAvJV+fRp6nYiIml9OYTm2nszEpuNZOJddpJtvb2WB4Z09MaqrN3r6OUMuN8zn7en9qf3DDz8gJiYGa9asQWRkJOLi4jBkyBAkJyfDzc3tnuXnzp2Lb7/9Fp999hk6dOiAnTt3YvTo0Th48CC6du2qWy4sLKzGQNHGXPli6pRKJTQaTYPLHThwABMnTsTo0aMBiGdcLl++3GJ1HThwAL1798Yrr7yim3fx4kXdn+3t7eHn54eEhAQMGjTonvXDw8Nx9epVXLhwgWdZiIhaUHF5JX45k4MtJzJx8OI1VF/3YamQYVCoG0Z39cagDm6waoaz/y1N71SwYsUKTJ06FZMmTQIArFmzBtu2bcPatWsxa9ase5b/5ptvMGfOHAwbNgwA8PLLLyM+Ph7//Oc/8e23394uxMJCN1aDRH5+fjhy5AguX74MOzu7Os9+BAcHY+PGjYiOjoZMJsO8efMadaakqYKDg/H1119j586d8Pf3xzfffIM//vgD/v7+umUWLlyIadOmwc3NTTfA9sCBA3j99dcxYMAA9O/fH0888QRWrFiBoKAgnD9/HjKZrMHxM0REVD91lRa/XcjHphOZiD+bi4qq258HPfzaYFRXbwzv7AknG6WEVepPr8CiVquRmJiI2bNn6+bJ5XJERUXh0KFDta5TUVFxz9N1ra2tsX///hrzUlJS4OXlBSsrK/Tq1QuxsbF1XuFSUVGBiooK3fdFRUW1LmfsZsyYgQkTJqBjx464desWvvjii1qXW7FiBV544QX07t0bLi4uePvtt1v07+Sll17C8ePHMW7cOMhkMowfPx6vvPIKfvnlF90yEyZMQHl5OVauXIkZM2bAxcUFY8aM0b2+YcMGzJgxA+PHj0dpaSmCgoLw3nvvtVjNRESmTBAEHEu/ic3HM/HzqSzcKKvUvRboaovHH2yHERFe8HG2kbDK+yMTGntjEABZWVnw9vbGwYMH0atXL938mTNnYt++fboxDHd6+umncfLkSWzevBmBgYFISEjAyJEjodFodKHjl19+QUlJCUJDQ5GdnY1FixYhMzMTZ86cgb39vYN+ahvzAgCFhYVwcHCoMa+8vBxpaWnw9/e/JziR8eBxJCK616X8Emw+kYXNxzORfr1MN9/VXoUREV4Y3dUbYV4OkMkMc1xKUVERHB0da/38vluLDxRZtWoVpk6dig4dOkAmkyEwMBCTJk3C2rVrdcsMHTpU9+fw8HBERkbC19cX69atw+TJk+/Z5uzZsxETE6P7vqioCD4+Pi27I0RERAagoKQCP50UQ8rJq4W6+TZKBR7t5IFRXbzRO7AtLBSmdW9YvQKLi4sLFAoFcnNza8zPzc2tc/yJq6srNm/ejPLycly7dg1eXl6YNWtWvffdcHJyQkhICFJTU2t9XaVSQaVS6VM66WHatGk1xhfd6dlnn8WaNWtauSIiIvNWpq7CrrO52HQ8E7+nFECjFZsjCrkM/YNdMKqrNx7u6G7UV8A2RK89UyqV6NatGxISEjBq1CgA4l1LExIS6r1BGQBYWVnB29sblZWV2LBhg+4GY7UpKSnBxYsX8dxzz+lTHjWTxYsXY8aMGbW+1tApOyIiah5VGi0OXLyGLcczsSMpB2Xq21eNRvg4YXQXLzwW4QUXO/P4BV7vKBYTE4MJEyage/fu6NmzJ+Li4lBaWqq7auj555+Ht7c3YmNjAQBHjhxBZmYmunTpgszMTCxcuBBarRYzZ87UbXPGjBmIjo6Gr68vsrKysGDBAigUCt1dWKl1ubm51XqJOhERtSxBEHAms0i8qdvJLBSU3L7AxLetDUZ28caoLl4IcLWTsEpp6B1Yxo0bh/z8fMyfPx85OTno0qULduzYAXd3dwBAeno65PLbfbPy8nLMnTsXly5dgp2dHYYNG4ZvvvkGTk5OumWuXr2K8ePH49q1a3B1dUXfvn1x+PBhPmGYiIjMQvUTkTcdz8TF/FLd/DY2loiO8MKort7o6uNksINnW4NeVwkZqvpGGfPqEtPA40hEpuZmmRrbTmdj8/FM/HH5hm6+ykKOhzu6Y3RXb/QPcYWliQ2evZNBXSVEREREosY8EfnRTh6wt7JsYEvmh4GFiIioBdX3ROSOng4YZUBPRDZkDCxEREQtwBifiGzIGFhMmJ+fH6ZPn47p06dLXQoRkVnILryFrSeysPmEcT4R2ZAxsBAREd2H6icibz6eiUOXaj4R+aEO4hORB4YaxxORDRkDCxERkZ7qeyJyTz9njOrqjWGdPYzuiciGzHSvlaqPIAClpdJMjbyK/N///je8vLyg1WprzB85ciReeOEFXLx4ESNHjoS7uzvs7OzQo0cPxMfHN/mvZMWKFejcuTNsbW3h4+ODV155BSUlJTWWOXDgAAYOHAgbGxu0adMGQ4YMwY0b4qV4Wq0W77//PoKCgqBSqdC+fXssWbKkyfUQERkaQRCQeOUG5m0+g8il8Zjy9Z/YdiobFVVaBLra4q0hofh95iCsm9YLT0e2Z1hpZuZ5hqWsDLCT6C6BJSWArW2Di40dOxavv/469uzZg8GDBwMArl+/jh07dmD79u0oKSnBsGHDsGTJEqhUKnz99deIjo5GcnIy2rdvr3dZcrkcH374Ifz9/XHp0iW88sormDlzJj755BMAwIkTJzB48GC88MILWLVqFSwsLLBnzx5oNOKtomfPno3PPvsMK1euRN++fZGdnY3z58/rXQcRkaEx9icimwrzvHFcaanBBxYAGDVqFNq2bYvPP/8cgHjWZdGiRcjIyKhxN+FqnTp1wrRp03TPdbqfQbfr16/HtGnTUFBQAAB4+umnkZ6ejv3799+zbHFxMVxdXfHxxx9jypQpev+sxuCN44ioNeUXV+DnU+b3ROTWxhvHNcTGRgwOUv3sRnrmmWcwdepUfPLJJ1CpVPjuu+/w1FNPQS6Xo6SkBAsXLsS2bduQnZ2Nqqoq3Lp1C+np6U0qKz4+HrGxsTh//jyKiopQVVWF8vJylJWVwcbGBidOnMDYsWNrXffcuXOoqKjQnQkiIjJGfCKyYTPPv3WZrNFnOaQUHR0NQRCwbds29OjRA7///jtWrlwJQHxg5K5du/DBBx8gKCgI1tbWGDNmDNRqtd4/5/Lly3jsscfw8ssvY8mSJXB2dsb+/fsxefJkqNVq2NjYwNraus7163uNiMiQ8YnIxsM8A4uRsLKywuOPP47vvvsOqampCA0NxYMPPghAHAA7ceJEjB49GgBQUlKCy5cvN+nnJCYmQqvV4p///Keu1bRu3boay4SHhyMhIQGLFi26Z/3g4GBYW1sjISGhxVpCRETNpaEnIo/q4o1RXb3h72L4v9iaEwYWA/fMM8/gscceQ1JSEp599lnd/ODgYGzcuBHR0dGQyWSYN2/ePVcUNVZQUBAqKyvx0UcfITo6GgcOHMCaNWtqLDN79mx07twZr7zyCqZNmwalUok9e/Zg7NixcHFxwdtvv42ZM2dCqVSiT58+yM/PR1JSEiZPnnxf+09E1Fz4RGTjxsBi4B566CE4OzsjOTkZTz/9tG7+ihUr8MILL6B37966wFBUVFTPluoWERGBFStWYNmyZZg9ezb69++P2NhYPP/887plQkJC8Ouvv+Kdd95Bz549YW1tjcjISIwfPx4AMG/ePFhYWGD+/PnIysqCp6cnpk2bdn87T0R0n/hEZNNhnlcJkdHhcSSixiqv1GD3X09E3nvXE5H7BIqDZ4eEufOJyAaAVwkREZFZaeiJyKO7eiM6wotPRDZiDCxm4LvvvsNLL71U62u+vr5ISkpq5YqIiJpH9RORt5zIRDafiGzSGFjMwIgRIxAZGVnra5aWPCVKRMaFT0Q2TwwsZsDe3h729vwNg4iMF5+ITGYTWExgbLFZ4/EjMj98IjLdyeQDS3XLo6ysjHdkNWJlZeIDx9jCIjJtgiDgWPoNbDqeiW2nsnGjrFL3WpCbHUZ39caICC/4ODf+MSdkGkw+sCgUCjg5OSEvLw8AYGNjw5sCGRFBEFBWVoa8vDw4OTlBoeDpXiJTdDG/BFuOZ2Lziax7nog88q+buvGJyObN5AMLAHh4eACALrSQ8XFyctIdRyIyDQ09EXl0V2/0DnSBgoNnCWYSWGQyGTw9PeHm5obKysqGVyCDYmlpyTMrRCaCT0SmpjKrfxEKhYIffEREray+JyJ38XHCKD4RmRrBrAILERG1niqNFptPZOGj3Sm4cu32uBQ+EZmagoGFiIialUYrYOvJTHyYkIq0AvGpyE42lhjBJyLTfWBgISKiZqHRCvj5VBZWJaTgUr4YVJxtlXixfwCe7+XLcSl0X/ivh4iI7otWK2Db6WysSkhBal4JAPGMyov9AzChlx9sVfyoofvHf0VERNQkWq2AHUk5WBWfguTcYgCAo7Ulpvbzx4TefrC34o0eqfkwsBARkV4EQcDOpFzExV/A+RwxqNhbWWBK3wBM6usHBwYVagEMLERE1CiCIGDX2VzExafg7F9PSbZXWeCFvv54oa8/HK0ZVKjlMLAQEVG9BEHA7vN5iItPwelM8Y60dioLTOrjh8l9/fnwQWoVDCxERFQrQRCw90I+4nZd0N0630apwMTefpjaLwBtbBlUqPUwsBARUQ2CIOC3lAKs3HUBJzJuAgCsLRV4vrcvXuwXgLa8Iy1JgIGFiIgAiEHlQOo1rIy/gMQrNwAAVpZyPN/LDy/2D+Ct80lSDCxERISDF8UzKn9cFoOKykKOZ//mi5cGBMDN3kri6ogYWIiIzNrhS9ewctcFHEm7DgBQWsjxdM/2eGVgINwcGFTIcDCwEBGZoT8uX8fKXRdw8OI1AIBSIcf4nj54eWAQPBwZVMjwMLAQEZmRxCs3EBd/Ab+nFAAALBUyjOvhg1cGBsHLyVri6ojqxsBCRGQGjqffwMr4FPx2IR8AYCGXYWx3H7w6KBDt2thIXB1RwxhYiIhM2KmrN7Fy1wXsSRaDikIuw9hu7fDqoCD4ODOokPFgYCEiMkFnMgsRF38B8efyAIhB5fGu3nj9oWC0b8ugQsaHgYWIyIQkZRUiLj4Fu87mAgDkMmBUV2/830PB8HOxlbg6oqZjYCEiMgHnc4oQtysFO5JyAAAyGTAywgv/NzgYAa52EldHdP8YWIiIjNiF3GKsik/BttPZAMSgEh0uBpUgNwYVMh0MLERERig1rxirElLx86ksCII4b3i4J94YHIwQd3tpiyNqAQwsRERG5GJ+CT5MSMHWk7eDytBOHngjKhgdPBykLY6oBTGwEBEZgbSCUnyUkILNJzKh/SuoPNLRHdOjQtDRi0GFTB8DCxGRAbtyrRQf7U7FpuOZ0PyVVKIecMf0qGB08naUuDqi1sPAQkRkgDKul+Gj3SnYcOx2UHmogxumRwUjvJ2TtMURSYCBhYjIgFy9UYbVe1Lx459XUfVXUBkQ4oo3Hw5BFx8naYsjkhADCxGRAci6eQur96Ri3Z8ZqNSIQaVfsAumR4Wgm28biasjkh4DCxGRhHIKy/HJ3lR8fzQDao0WANAnqC3ejApBdz9niasjMhwMLEREEsgtKse/9l7Ef4+mQ10lBpW/BTjjzagQRAa0lbg6IsPDwEJE1IryisuxZu8lfHfkCir+Cio9/cWg0iuQQYWoLgwsREStoKCkAp/uu4hvDl9BeaUYVLr7tsGbD4egd2BbyGQyiSskMmwMLERELehaSQX+/dslfH3oCm5VagAAXds74c2oEPQLdmFQIWokBhYiohZwo1SNf/9+CV8dvIwytRhUIto54s2HQzAgxJVBhUhPDCxERM3oZpka//k9DV8cSEPpX0Gls7cj3nw4GINC3RhUiJqIgYWIqBkUllXi8/2X8MWByyiuqAIAhHk5YHpUCKIeYFAhul8MLERE96GovBJr96fh8/1pKC4Xg0oHD3u8+XAIHunozqBC1EwYWIiImqC4vBJfHriMz36/hKK/gkqouz2mRwVjSJgH5HIGFaLmxMBCRKSHkooqfHVQDCo3yyoBAMFudngjKhjDOnkyqBC1EAYWIqJGKK2owteHruDfv13Ejb+CSoCrLaZHhWB4Z08oGFSIWhQDCxFRPW6pNfjm8GV8uu8SrpWqAQD+LrZ4Y3AwoiO8GFSIWgkDCxFRLcorNfj28BWs2XcRBSViUPFta4P/eygYI7t4wUIhl7hCIvPCwEJEdIfySg3+eyQd/9p3EfnFFQAAH2dr/N9DwRjd1ZtBhUgiTXrnrV69Gn5+frCyskJkZCSOHj1a57KVlZVYvHgxAgMDYWVlhYiICOzYseO+tklE1NzKKzX46uBlDFi+B4t/Pov84gp4O1lj2ROdsfvvAzG2uw/DCpGE9D7D8sMPPyAmJgZr1qxBZGQk4uLiMGTIECQnJ8PNze2e5efOnYtvv/0Wn332GTp06ICdO3di9OjROHjwILp27dqkbRIRNZeKKg3W/XkVq3enIqeoHADg7WSNVwcFYUy3dlBaMKQQGQKZIAiCPitERkaiR48e+PjjjwEAWq0WPj4+eP311zFr1qx7lvfy8sKcOXPw6quv6uY98cQTsLa2xrffftukbd6tqKgIjo6OKCwshIODgz67Q0RmSl2lxfrEq/h4dwqyCsWg4ulohVcHBWFs93ZQWSgkrpDI9Onz+a3XGRa1Wo3ExETMnj1bN08ulyMqKgqHDh2qdZ2KigpYWVnVmGdtbY39+/c3eZtERE1VqdFiQ+JVfLQ7FZk3bwEA3B1UeHVQEMb18GFQITJQegWWgoICaDQauLu715jv7u6O8+fP17rOkCFDsGLFCvTv3x+BgYFISEjAxo0bodFomrzNiooKVFRU6L4vKirSZzeIyAxVabTYeDwTH+1OQcZ1Mai42qvwysBAjO/ZHlaWDCpEhqzFrxJatWoVpk6dig4dOkAmkyEwMBCTJk3C2rVrm7zN2NhYLFq0qBmrJCJTVaXRYsuJLHy4OwVXrpUBAFzslJg2IBDP/s2XQYXISOgVWFxcXKBQKJCbm1tjfm5uLjw8PGpdx9XVFZs3b0Z5eTmuXbsGLy8vzJo1CwEBAU3e5uzZsxETE6P7vqioCD4+PvrsChGZOI1WwNaTmfgwIRVpBaUAgLa2t4OKtZJBhciY6DX8XalUolu3bkhISNDN02q1SEhIQK9evepd18rKCt7e3qiqqsKGDRswcuTIJm9TpVLBwcGhxkREBIhBZcuJTDyych/e/OEk0gpK0cbGErOGdsDvbw/C1P4BDCtERkjvllBMTAwmTJiA7t27o2fPnoiLi0NpaSkmTZoEAHj++efh7e2N2NhYAMCRI0eQmZmJLl26IDMzEwsXLoRWq8XMmTMbvU0iooZotQK2n8lGXHwKUvNKAABONpaY2i8AE3r7wU7F+2QSGTO938Hjxo1Dfn4+5s+fj5ycHHTp0gU7duzQDZpNT0+HXH77xE15eTnmzp2LS5cuwc7ODsOGDcM333wDJyenRm+TiKguWq2AHUk5WBWfguTcYgCAg5UFpvYLwMQ+frC3spS4QiJqDnrfh8UQ8T4sROZHEATsTMpFXPwFnM8Rg4q9lQWm9A3ApL5+cGBQITJ4LXYfFiIiqQmCgPhzeYiLv4CkLPGWBvYqC0zq64/Jff3haM2gQmSKGFiIyCgIgoDd5/MQF5+C05mFAABbpQKT+vhjSj9/ONkoJa6QiFoSAwsRGTRBELD3Qj7idl3AyatiULFRKjCxtx+m9gtAG1sGFSJzwMBCRAYrNa8YC7Ym4UDqNQCAtaUCz/f2xYv9AtDWTiVxdUTUmhhYiMjglFRU4cOEFKzdn4YqrQClhRwTevnipQGBcGFQITJLDCxEZDAEQcBPp7KxZNtZ5BaJzwuLesAN8x8LQ/u2NhJXR0RSYmAhIoNwIbcYC7Yk4dAlsf3T3tkGC0d0xEMdeD8mImJgISKJFZdXYlV8Cr48eBlVWgEqCzleHRSEF/sH8MGERKTDwEJEkhAEAVtOZGHJ9nPILxbbP490dMe8xzrCx5ntHyKqiYGFiFrd+ZwizN+ShKNp1wEAfm1tsHBEGAaGuklcGREZKgYWImo1ReWVWLnrAr4+dAUarQArSzlefygYU/r5Q2XB9g8R1Y2BhYhanCAI2HgsE7G/nEdBidj+GdrJA3Mf6whvJ2uJqyMiY8DAQkQt6mxWEeZvOYM/r9wAAAS42mLRiDD0C3aVuDIiMiYMLETUIgpvVWLFr8n45vAVaAXxdvqvPxSMyX39obSQS10eERkZBhYialZarYD1x65i2S/nca1UDQAYHu6JucMfgKcj2z9E1DQMLETUbM5kFmL+ljM4ln4TABDkZodFI8LQJ8hF2sKIyOgxsBDRfbtZpsYHvybjuyPpEATAVqnAG1HBmNib7R8iah4MLETUZFqtgHV/ZuD9ncm4/lf7Z0SEF94Z9gA8HK0kro6ITAkDCxE1yamrNzFvSxJOZtwEAIS422HRiE7oFdhW2sKIyCQxsBCRXm6UqrH812T876jY/rFTWWB6VDAm9PaDpYLtHyJqGQwsRNQoGq2A7/9Ix/KdybhZVgkAGN3VG7OHdoCbA9s/RNSyGFiIqEEnMm5i/pYzOHW1EADQwcMei0d2Qk9/Z4krIyJzwcBCRHW6XqrG+zvO44c/MyAIgL3KAm8+HILne/nCgu0fImpFDCxEdA+NVsB/j6bjg53JKLwltn+eeLAd3h4aCjd7tn+IqPUxsBBRDYlXbmDB1jM4k1kEAOjo6YDFI8PQ3Y/tHyKSDgMLEQEACkoqsOyX8/gx8SoAwN7KAjMeCcUzke3Z/iEiyTGwEJm5Ko0W3x1Jxz9/TUZReRUAYGy3dnh7aAe42Kkkro6ISMTAQmTG/rx8HfO2JOFcttj+CfNywOKRndDNt43ElRER1cTAQmSG8osrEPvLOWw8lgkAcLS2xIwhoXi6Z3so5DKJqyMiuhcDC5EZqdJo8fWhK1i56wKKK6ogkwHjuvtg5qMd4GyrlLo8IqI6MbAQmYkjl65hwdYknM8pBgCEt3PE4pGd0MXHSdrCiIgagYGFyMTlFZVj6fZz2HwiCwDgZGOJmUM6YFwPH7Z/iMhoMLAQmahKjRZfHbyMuPgUlPzV/hnfsz3eeiQUbdj+ISIjw8BCZIIOXbyGBVvP4EJuCQAgwscJ744MQ3g7J2kLIyJqIgYWIhOSU1iOJdvP4aeTYvvH2VaJtx8NxdhuPpCz/UNERoyBhcgEVGq0+OJAGlbFp6BUrYFMBjwb6Yu/PxICJxu2f4jI+DGwEBm5A6kFWLA1Cal5YvvnwfZOWDyyEzp5O0pcGRFR82FgITJS2YW38I+fz2Hb6WwAQFtbJWYN7YAnHmzH9g8RmRwGFiIjo67S4vP9afhodwrK1BrIZcDzvfzw5sMhcLS2lLo8IqIWwcBCZER+T8nHgq1JuJRfCgDo7tsGi0aGIcyL7R8iMm0MLERGIPPmLfzj57P45UwOAMDFToXZQzvg8Qe9IZOx/UNEpo+BhciAVVRp8J/fxfZPeaUWCrkME3r5YfrDwXCwYvuHiMwHAwuRgdqbnIdFP51FWoHY/unp54zFo8LQwcNB4sqIiFofAwuRgcm4XoZ3fz6LX8/mAgBc7VWYM+wBjOzixfYPEZktBhYiA1FeqcG/f7uE1XtSUVEltn8m9fbDG1HBsGf7h4jMHAMLkQHYfT4Xi346iyvXygAAfwtwxuKRnRDibi9xZUREhoGBhUhC6dfKsPjnJMSfywMAuDuoMGd4R0SHe7L9Q0R0BwYWIgmUV2rwr70X8a99F6Gu0sJCLsPkvv54fXAw7FR8WxIR3Y3/MxK1IkEQEH8uD4t/TkLG9VsAgD5BbbFoRBiC3Nj+ISKqCwMLUSu5XFCKRT8lYU9yPgDA09EKc4d3xLDOHmz/EBE1gIGFqIXdUmvwyd5UfLrvEtQaLSwVMkzpF4DXBgXBlu0fIqJG4f+WRC1EEAT8ejYXi386i8ybYvunX7ALFo4IQ6CrncTVEREZFwYWohaQVlCKhVuTsO+C2P7xdrLGvMcewJAwtn+IiJqCgYWoGZWpq7B6Tyo++y0Nao0WSoUcL/YPwKuDgmCtVEhdHhGR0WJgIWoGgiBgx5kcvPvzWWQVlgMABoa6YkF0GPxdbCWujojI+DGwEN2ni/klWLg1Cb+nFAAQ2z8Lojvi4Y7ubP8QETUTBhaiJiqtqMJHu1Px+f5LqNQIUFrIMW1AIF4eEMj2DxFRM2NgIdKTIAjYdjobS7adQ/Zf7Z/BHdwwP7ojfNuy/UNE1BIYWIj0kJpXjPlbknDw4jUAgI+zNRY8Foaoju4SV0ZEZNoYWIgaoaSiCh8mpGDt/jRUaQWoLOR4eWAgpg0IhJUl2z9ERC2NgYWoHoIgYOvJLCzdfg65RRUAgKgH3LEguiN8nG0kro6IyHwwsBDVITmnGAu2nsHhS9cBAL5tbbAwOgyDOrhJXBkRkflhYCG6S3F5JeLiU/DlwcvQaAVYWcrx6sAgTO0fwPYPEZFEGFiI/iIIAjafyMTS7eeRXyy2f4aEuWPeYx3Rrg3bP0REUmJgIQJwLrsIC7Yk4ehlsf3j72KLhSPCMCDEVeLKiIgIYGAhM1d4qxIrd13AN4evQKMVYG2pwGsPBWFKP3+oLNj+ISIyFAwsZJa0WgEbj2fivV/OoaBEDQAY1tkDc4Z3hLeTtcTVERHR3RhYyOwkZRVi/pYkJF65AQAIcLXFohFh6BfM9g8RkaFiYCGzUXirEit+TcY3h69AKwA2SgX+b3AwXujjD6WFXOryiIioHk36X3r16tXw8/ODlZUVIiMjcfTo0XqXj4uLQ2hoKKytreHj44M333wT5eXlutcXLlwImUxWY+rQoUNTSiO6h1YrYN0fGXjog7346pAYVh4L90TC3wdg2oBAhhUiIiOg9xmWH374ATExMVizZg0iIyMRFxeHIUOGIDk5GW5u995Q67///S9mzZqFtWvXonfv3rhw4QImTpwImUyGFStW6JYLCwtDfHz87cIsePKH7t+NUjWmfP2nrv0T5GaHxSPC0DvIReLKiIhIH3qnghUrVmDq1KmYNGkSAGDNmjXYtm0b1q5di1mzZt2z/MGDB9GnTx88/fTTAAA/Pz+MHz8eR44cqVmIhQU8PDyasg9EdVr4kzhWxVapwPSoEEzs4wdLBc+oEBEZG73+51ar1UhMTERUVNTtDcjliIqKwqFDh2pdp3fv3khMTNS1jS5duoTt27dj2LBhNZZLSUmBl5cXAgIC8MwzzyA9Pb3OOioqKlBUVFRjIrrbrrO52HIiC3IZ8N3Uv2Fq/wCGFSIiI6XXGZaCggJoNBq4u7vXmO/u7o7z58/Xus7TTz+NgoIC9O3bF4IgoKqqCtOmTcM777yjWyYyMhJffvklQkNDkZ2djUWLFqFfv344c+YM7O3t79lmbGwsFi1apE/pZGYKyyoxZ9NpAMDU/gHo4uMkbUFERHRfWnygyN69e7F06VJ88skniIyMRGpqKt544w28++67mDdvHgBg6NChuuXDw8MRGRkJX19frFu3DpMnT75nm7Nnz0ZMTIzu+6KiIvj4+LT0rpARWbL1FALPHMXcK0cQ/b8TgJUVEBoKhISIX6v/7O4OyGRSl0tERA3QK7C4uLhAoVAgNze3xvzc3Nw6x5/MmzcPzz33HKZMmQIA6Ny5M0pLS/Hiiy9izpw5kMvvPUXv5OSEkJAQpKam1rpNlUoFlUqlT+lkDqqqgN9+Q+ZnX2Pm1s1wKSus+fqFC/eu4+BwO8Tc+TUkBLC1bZ26iYioQXoFFqVSiW7duiEhIQGjRo0CAGi1WiQkJOC1116rdZ2ysrJ7QolCId7yXBCEWtcpKSnBxYsX8dxzz+lTHpmjv0IKfvwR2LAByM+H918vldk7wubJMcATTwBKJZCcLIaW6q+XLwNFRcCff4rT3by97w0yoaGAry/Aq9iIiFqV3v/rxsTEYMKECejevTt69uyJuLg4lJaW6q4aev755+Ht7Y3Y2FgAQHR0NFasWIGuXbvqWkLz5s1DdHS0LrjMmDED0dHR8PX1RVZWFhYsWACFQoHx48c3466SyagOKevWARs3Avn5upfK7ByxJSASf/YYjHdXvQ7Y3nGb/cGDa26nvBy4dOneIJOcDBQUAJmZ4rR7d831LC2BoKDaz8y4urLFRETUAvQOLOPGjUN+fj7mz5+PnJwcdOnSBTt27NANxE1PT69xRmXu3LmQyWSYO3cuMjMz4erqiujoaCxZskS3zNWrVzF+/Hhcu3YNrq6u6Nu3Lw4fPgxXV94qnf5SVQXs2yeeSbkrpMDZGXj8cST1fgQjzypRpbDA/6b+DTa2DTwTyMoK6NhRnO52/fq9IebCBSAlRQw6586J092cnGoPMsHBgI3Nff0VEBGZM5lQV1/GiBQVFcHR0RGFhYVwcHCQuhxqLvWFlLZtgdGjgbFjgUGDUKqVYUjcb7h64xae+5sv3h3VqWVq0mqBjIzaz8qkpwP1vZ18fGpvMbVvDyj4ZGgiMj/6fH6zEU+GpTEh5ckngYEDxdbMX5ZvTcLVG7fg7WSNt4e24GMd5HJxDIuvL/DIIzVfu3ULSE29N8gkJwM3bohBJyMDuOOOzgAAlaruFpML78hLRAQwsJAhqA4p69YBmzY1OqRUO5p2HV8evAwAeO+JzrBTSfTP2toa6NxZnO5WUFB3i6miAkhKEqe7OTvXHmSCgsSfR0RkJhhYSBpVVcDevbfPpBQU3H6tbVvg8cfFdk8dIaXaLbUGM9efBACM6+6DfsEGOu7JxUWceveuOV+jEVtJtbWYMjLEsTSHD4vTnWQysZVUW4vJx0c8E0REZEI4hoVaTzOFlDst2XYWn/2eBg8HK/wa0x8OVo1bzyiUlYlnYGprMRUW1r2elZU4yLe2MzPOzq1XPxFRAziGhQxHY0PKoEF639vkWPoNfL4/DQCw9PFOphVWAPGqoogIcbqTIIhts9paTKmp4lVMp0+L091cXOpuMfFmjERkwBhYqPlVh5TqMSm1hZTqMSlNvAFbeaUGM9efglYAHu/qjYc6uDe8kqmQyQA3N3Hq27fma1VVwJUrtbeYMjPFY1FQABw8WHO96sHEtbWYvL3ZYiIiybElRM2jvpDi4lKz3dMMd4l9f8d5fLL3IlzsVIiP6Q8nG+V9b9PklZTU3WIqLq57PRubultMTk6tVj4RmR62hKh1VFUBe/aI7Z5WCCnVTl8txKe/XQIA/GNUJ4aVxrKzA7p2Fac7CQKQm1t7i+niRXEszcmT4nQ3N7faz8oEBIiPQyAiaiYMLKSfO0PKxo3AtWu3X2vBkFJNXaXFW+tPQqMV8Fi4Jx7tVPtDN0kPMhng4SFO/fvXfK2yEkhLqz3MZGcDeXni9PvvNddTKAB//9rPynh58fEFRKQ3toSoYY0JKU8+CQwY0OIPBVy56wJWJaTA2VaJXW/2R1s7DhSVTFGR2GK6O8hcuCC2n+pia1v3E7L5/iUyK2wJ0f2rDinVY1IkDCnVzmUXYfWeVADAohFhDCtSc3AAunUTpzsJgnj2pbaBv2lpQGkpcPy4ON3Nw6P2FpO/f6MvdSci08TAQrdVVtYck3J3SHniCbHd04ohRVeaRmwFVWkFPNLRHY+Fe7bqzyc9yGRi28fLS7xc/U5qtfiE7NpaTLm5QE6OOO3bV3M9hUK8WsnXV7xhXvV05/f29q23j0TU6hhYzF19IcXV9faYFAlCyp3+/dslnMksgqO1Jf4xuhNkHANhnJRKoEMHcbrbzZt1t5jKysQ7Aqen171tJ6f6A42HBx8ySWTEGFjMkZGElGopucVYFZ8CAFgQ3RFu9lYSV0QtwskJ6NFDnO6k1YotpurAkp4u3mvmzu9v3BADz82btV/NBIgtpXbt6g407duL42uIyCBJ/2lEraM6pFSPSbl+/fZr1SHlySfFq0QMIKRU02gFvLX+FNQaLQaFumJ0V2+pS6LWJpeL7SBvb6BXr9qXKSoSn71UV6C5evX2FU9paXX/rLZt6w807u68iR6RRAznk4maX2UlsHv37TMpd4eU6jEpBhZS7rR2fxpOZNyEvcoCSx/vzFYQ1c7BAQgLE6faVFXVPEtzd6C5ckUMPdeuiVNtA4IBsaXl41N3oGnfnk/RJmohhvkpRU1nAiGl2qX8EnzwazIAYM7wB+DpyA8CaiILCzFo+PgAffrUvkxhYf2BJitLHDR88aI41cXVte5A4+srvs7gTaQ3w/7EosapL6S4ud0ek2IEIaWaVivg7Q2nUFGlRd8gF4zr4SN1SWTqHB2Bzp3FqTaVlWJoqSvQXLkiXrKdny9OiYm1b8fKSgxOdQ0QbtdOXIaIajCOTy+6V3VIWbcO2Ly59pBSPSbFCK+M+PrQZfxx+QZslArEshVEhsDSUgwVvr5Av373vi4I4qDfugJNerrYliovF6+GSkmp+2e5u9d/xVPbtjxLQ2aHgcWYmHhIqZZxvQzLdoitoNlDO8DH2UbiiogaQSYD2rQRp4iI2pdRq8WnZtcVaNLTxUu4c3PF6ejR2rdjY3Pv2Jk7A027dnyWE5kcBhZDV1kJJCSI7Z7aQsqdY1KMOKRUEwSxFXSrUoNIf2c8E+krdUlEzUepFO/a6+9f++uCIL7H6ws0OTliqDl/XpxqI5MBnp71X/HUpg3P0pBRYWAxRHeGlE2bxHtMVDPBkHKn/x3NwMGL12BlKceyJ8Ihl/M/VDIjMpnY7mnbFnjwwdqXqaioeQl3bS2o8nJxvE1WFnD4cO3bsbOrP9B4e/NxCGRQGFgMhRmHlGqZN29h6fZzAIC3hnSAnwtv4kV0D5UKCAoSp9oIAlBQUP9Zmrw88QGVZ8+KU23kcvHxCvVd8eTo2HL7SXQXBhYpVYeU6jEptYWUJ58UB/iZaEipJggCZm88jZKKKjzY3gkTe/tJXRKRcZLJxEunXV2B7t1rX+bWrYbP0qjV4g33rl4FDh6sfTsODvUHGk9Po7kykQwf/yW1NrW65piUO0OKu/vtMylmEFLutD7xKn67kA+lhRzvj4mAgq0gopZjbS0+CTskpPbXtVrxLEx9gaagQLzZ3pkz4lSb6odWVreYqgclOznV/dXJyaz+76PGY2BpDQwp9cotKse7P4unpd+MCkGQm53EFRGZOblcfFikhwfQs2fty5SW1v84hIwM8SxyQw+trI29fcPBpq6vNjYcTGyiGFhaCkNKowiCgDmbTqOovAoR7RwxtV8dV08QkWGxta37ydsAoNGIl2ZXB5asrNsPqKx+WOXdX0tKxHWLi8VJ36ADiAOFq8/U6Bt2nJzYwjJgPDLNqTqkVI9JuXnz9mvVIeXJJ4G+fc06pNxp68ksxJ/Lg6VChvfHRMBCwQfLEZkEhUIctOvlBfztb41bp7JSfERCXYGmvq83boghqbLy9t2Gm8LOrulnd2xteXanBTGw3C+GlCbLL67Agq1JAIDXHwpGqIe9xBURkaQsLQEXF3HSlyCIbSp9g0711+qzOyUl4pSRoX8NFhZNCzpt2ohXXPEy8noxsDSFWg3Ex99u99wdUsaMEds9DCn1WrD1DG6WVaKjpwNeHhgodTlEZMxkMvHsiJ2deKdffVVVNdyyqu9rVZU4FRSIU1PY2TU98JjB2R0GlsaqL6R4eNwek8KQ0ijbT2dj++kcWMhleH9MOCzZCiIiKVlY3N/ZnbKyultV+p7duXq1afXfz9gdIzi7w8BSH4aUFnG9VI35W8TLIF8eGIhO3rz5FBEZMZlMPMNha2u8Z3dsbWsGmLrCzXPPSfZ5x8BSn6tXgeHDb39fHVKefBLo04chpYkW/ZSEghI1Qtzt8NpDddytk4jIXLTU2Z3GfC0uFrdTWipO9Z3dsbAAJkzQv8ZmwsBSn4AA4LHHxDs2MqQ0i11nc7HlRBbkMmD5mAioLPj3SUTUZM1xdqexV2ZptZKOk2FgachPP0ldgckoLKvEnE2nAQBT+wcgwsdJ2oKIiMydhcXtB24aOI50pFbz7razyCuuQICLLd6MquOW4ERERLVgYKFWsTc5D+sTr0ImA94fEw4rS7aCiIio8RhYqMUVl1di9kaxFTSxtx+6+zlLXBERERkbBhZqcbG/nEd2YTnaO9vgrSGhUpdDRERGiIGFWtTB1AL894j4ALNlT4TDRslx3kREpD8GFmoxpRVVeHvjKQDAs39rj16Bhj8KnYiIDBMDC7WY5TuTkXH9FrydrDFr6ANSl0NEREaMgYVaxNG06/jy4GUAQOzjnWGnYiuIiIiajoGFmt0ttQYz158EAIzr7oP+Ia4SV0RERMaOgYWa3Ypdybh8rQzuDiq8M5ytICIiun8MLNSsjqXfwOf70wAAS0d3hqO14T+ynIiIDB8DCzWb8koNZq4/Ba0AjO7qjcEPuEtdEhERmQgGFmo2H+1OQWpeCVzsVFgQ3VHqcoiIyIQwsFCzOH21EGv2XQIA/GNUJzjZKCWuiIiITAkDC903dZUWb60/CY1WwPBwTzzayUPqkoiIyMQwsNB9+2RvKs7nFMPZVonFI8KkLoeIiEwQAwvdl3PZRfh4dyoAYOGIMLS1U0lcERERmSIGFmqyKo3YCqrSCnikozuiwz2lLomIiEwUAws12ae/XcKZzCI4WlviH6M6QSaTSV0SERGZKAYWapLUvGKsik8BAMx/rCPcHKwkroiIiEwZAwvpTaMV8Nb6U1BrtBgU6orHH/SWuiQiIjJxDCykt7X703A8/SbsVRZY+nhntoKIiKjFMbCQXtIKSvHBr8kAgDnDH4Cno7XEFRERkTlgYKFG02oFvL3+FCqqtOgb5IJxPXykLomIiMwEAws12jeHr+Do5euwUSoQy1YQERG1IgYWapSM62VYtuM8AGDW0A7wcbaRuCIiIjInDCzUIEEQ8PaGUyhTaxDp74xnI32lLomIiMwMAws16H9HM3Dw4jVYWcqx7IlwyOVsBRERUetiYKF6Zd68haXbzwEAZjwSCj8XW4krIiIic8TAQnUSBAHvbDyNkooqPNjeCZP6+EtdEhERmSkGFqrT+sSr2HchH0oLOd4fEwEFW0FERCQRBhaqVW5ROd79+SwA4M2oEAS52UlcERERmTMGFrqHIAiYs+kMisqrEN7OEVP7sRVERETSYmChe2w9mYX4c7mwVMiwfEwELBT8Z0JERNJq0ifR6tWr4efnBysrK0RGRuLo0aP1Lh8XF4fQ0FBYW1vDx8cHb775JsrLy+9rm9Qy8osrsGBrEgDg9YeCEephL3FFRERETQgsP/zwA2JiYrBgwQIcO3YMERERGDJkCPLy8mpd/r///S9mzZqFBQsW4Ny5c/j888/xww8/4J133mnyNqnlLNh6BjfLKvGApwNeHhgodTlEREQAAJkgCII+K0RGRqJHjx74+OOPAQBarRY+Pj54/fXXMWvWrHuWf+2113Du3DkkJCTo5v3973/HkSNHsH///iZt825FRUVwdHREYWEhHBwc9NkdusP209l45btjUMhl2PJqH3TydpS6JCIiMmH6fH7rdYZFrVYjMTERUVFRtzcglyMqKgqHDh2qdZ3evXsjMTFR1+K5dOkStm/fjmHDhjV5mxUVFSgqKqox0f25XqrG/C1nAAAvDwhkWCEiIoNioc/CBQUF0Gg0cHd3rzHf3d0d58+fr3Wdp59+GgUFBejbty8EQUBVVRWmTZumawk1ZZuxsbFYtGiRPqVTAxb/lISCEjWC3ezw+uAgqcshIiKqocUv/9i7dy+WLl2KTz75BMeOHcPGjRuxbds2vPvuu03e5uzZs1FYWKibMjIymrFi8xN/NhebT2RBLgOWj42AykIhdUlEREQ16HWGxcXFBQqFArm5uTXm5+bmwsPDo9Z15s2bh+eeew5TpkwBAHTu3BmlpaV48cUXMWfOnCZtU6VSQaVS6VM61aGwrBLvbDoNAJjaLwBdfJykLYiIiKgWep1hUSqV6NatW40BtFqtFgkJCejVq1et65SVlUEur/ljFArxN3hBEJq0TWo+/9h2FnnFFQhwscWbD4dIXQ4REVGt9DrDAgAxMTGYMGECunfvjp49eyIuLg6lpaWYNGkSAOD555+Ht7c3YmNjAQDR0dFYsWIFunbtisjISKSmpmLevHmIjo7WBZeGtkktY29yHn5MvAqZDHh/TDisLNkKIiIiw6R3YBk3bhzy8/Mxf/585OTkoEuXLtixY4du0Gx6enqNMypz586FTCbD3LlzkZmZCVdXV0RHR2PJkiWN3iY1v+LySryzUWwFTezth+5+zhJXREREVDe978NiiHgfFv29s+k0/nskHe2dbbBjej/YKPXOrkRERPelxe7DQqbhYGoB/nskHQDw3hOdGVaIiMjgMbCYmdKKKry98RQA4JnI9ugd6CJxRURERA1jYDEzy3cmI+P6LXg7WWP2sAekLoeIiKhRGFjMyNG06/jy4GUAwNLHO8NOxVYQEREZBwYWM3FLrcHbG8RW0JPd22FAiKvEFRERETUeA4uZWBl/AWkFpXB3UGHO8I5Sl0NERKQXBhYzcDz9Bv7z+yUAwNLRneFobSlxRURERPphYDFxFVUavLX+FLQCMLqrNwY/wJvxERGR8WFgMXEfJqQgNa8ELnYqzH+MrSAiIjJODCwm7PTVQqzZJ7aC/jEqDG1slRJXRERE1DQMLCZKXaXFW+tPQqMVMLyzJx7t5Cl1SURERE3GwGKiPtmbivM5xXC2VWLRyDCpyyEiIrovDCwm6Fx2ET7enQoAWDgiDC52KokrIiIiuj8MLCamSqPFzPWnUKUV8HBHd0SHsxVERETGj4HFxHz62yWcziyEg5UFlozqBJlMJnVJRERE942BxYSk5hVjVXwKAGB+dBjcHKwkroiIiKh5MLCYCI1WwFvrT0Gt0WJgqCueeNBb6pKIiIiaDQOLifjiQBqOp9+EncoCS0d3ZiuIiIhMCgOLCUgrKMXynckAgDnDH4CXk7XEFRERETUvBhYjp9UKeHv9KVRUadEnqC2e6uEjdUlERETNjoHFyH1z+AqOXr4OG6UC7z0ezlYQERGZJAYWI5ZxvQzLdpwHAMwa2gE+zjYSV0RERNQyGFiMlCAIeHvDKZSpNejp74xnI32lLomIiKjFMLAYqf8dzcDBi9dgZSnH+0+EQy5nK4iIiEwXA4sRyrp5C0u3nwMAzHgkFH4uthJXRERE1LIYWIyMIAiYvfE0Siqq8GB7J0zq4y91SURERC2OgcXIbDiWiX0X8qG0kOP9MRFQsBVERERmgIHFiOQWlWPxT0kAgOlRwQhys5O4IiIiotbBwGIkBEHAnE1nUFRehc7ejnixX4DUJREREbUaBhYjsfVkFuLP5cJSIcPyseGwUPDQERGR+eCnnhHIL67Awq1iK+i1QcHo4OEgcUVERESti4HFCCzcmoQbZZXo4GGPlwcGSl0OERFRq2NgMXC/nM7GttPZUMhl+GBsBJQWPGRERGR++OlnwG6UqjFvyxkAwMsDAtHJ21HiioiIiKTBwGLAFv2UhIISNYLd7PD64CCpyyEiIpIMA4uBij+bi80nsiCXAe+PCYfKQiF1SURERJJhYDFAhbcq8c6m0wCAKf0C0LV9G4krIiIikhYDiwH6x89nkVdcAX8XW8Q8HCJ1OURERJJjYDEw+y7k48fEq5D91QqysmQriIiIiIHFgBSXV2L2hlMAgAm9/NDDz1niioiIiAwDA4sBee+X88gqLIePszVmPhoqdTlEREQGg4HFQBxMLcB3R9IBAMueCIeN0kLiioiIiAwHA4sBKK2owtsbxVbQM5Ht0TvQReKKiIiIDAsDiwFYvjMZGddvwcvRCrOGdpC6HCIiIoPDwCKxPy5fx1eHLgMAYp8Ih72VpbQFERERGSAGFgmVV2owc/0pCAIwtls7DAhxlbokIiIig8TAIqEVuy4graAU7g4qzH2so9TlEBERGSwGFokcT7+B//x+CQCwdHRnOFqzFURERFQXBhYJVFRp8Nb6U9AKwKguXhj8gLvUJRERERk0BhYJfJiQgtS8ErjYKbEgOkzqcoiIiAweA0srO5NZiDX7xFbQuyM7oY2tUuKKiIiIDB8DSytSV2kx48eT0GgFDO/siaGdPaUuiYiIyCgwsLSif+29iPM5xWhjY4lFI9kKIiIiaiwGllZyPqcIH+9JAQAsHBEGFzuVxBUREREZDwaWVlCl0eKtH0+hUiPg4Y7uGBHhJXVJRERERoWBpRX8+/dLOJ1ZCAcrCywZ1QkymUzqkoiIiIwKA0sLS80rRtwusRU0PzoMbg5WEldERERkfBhYWpBGK+Ct9aeg1mgxMNQVTzzoLXVJRERERomBpQV9cSANx9Nvwk5lgaWjO7MVRERE1EQMLC0kraAUy3cmAwDeGfYAvJysJa6IiIjIeDGwtACtVsDbG06hokqLPkFtMb6nj9QlERERGTUGlhbwzeErOJp2HTZKBd57PJytICIiovvEwNLMMq6XYdmO8wCAtx/tAB9nG4krIiIiMn4MLM1IEATM2ngKZWoNevo547m/+UpdEhERkUlgYGlG3/+RgQOp16CykGPZmHDI5WwFERERNQcGlmaSdfMWlmw7BwB4a0go/F1sJa6IiIjIdDCwNANBEPDOptMoqahC1/ZOmNTHX+qSiIiITAoDSzPYcCwTe5PzobSQY/mYcCjYCiIiImpWDCz3KbeoHIt/SgIATI8KRpCbvcQVERERmZ4mBZbVq1fDz88PVlZWiIyMxNGjR+tcduDAgZDJZPdMw4cP1y0zceLEe15/9NFHm1JaqxIEAXM2nUFReRU6ezvixX4BUpdERERkkiz0XeGHH35ATEwM1qxZg8jISMTFxWHIkCFITk6Gm5vbPctv3LgRarVa9/21a9cQERGBsWPH1lju0UcfxRdffKH7XqVS6Vtaq9t6Mgvx53JhqZBh+dhwWCh4woqIiKgl6P0Ju2LFCkydOhWTJk1Cx44dsWbNGtjY2GDt2rW1Lu/s7AwPDw/dtGvXLtjY2NwTWFQqVY3l2rRp07Q9aiUFJRVYuFVsBb06KAgdPBwkroiIiMh06RVY1Go1EhMTERUVdXsDcjmioqJw6NChRm3j888/x1NPPQVb25qX/e7duxdubm4IDQ3Fyy+/jGvXrtW5jYqKChQVFdWYWtuCLUm4UVaJDh72eGVgUKv/fCIiInOiV2ApKCiARqOBu7t7jfnu7u7IyclpcP2jR4/izJkzmDJlSo35jz76KL7++mskJCRg2bJl2LdvH4YOHQqNRlPrdmJjY+Ho6KibfHxa9+GCv5zOxrbT2VDIZfhgbASUFmwFERERtSS9x7Dcj88//xydO3dGz549a8x/6qmndH/u3LkzwsPDERgYiL1792Lw4MH3bGf27NmIiYnRfV9UVNRqoeVGqRrztpwBAEwbEIBO3o6t8nOJiIjMmV6nBlxcXKBQKJCbm1tjfm5uLjw8POpdt7S0FN9//z0mT57c4M8JCAiAi4sLUlNTa31dpVLBwcGhxtRaFv2UhIISNYLc7PB/g4Nb7ecSERGZM70Ci1KpRLdu3ZCQkKCbp9VqkZCQgF69etW77o8//oiKigo8++yzDf6cq1ev4tq1a/D09NSnvBYXfzYXm09kQS4Dlo8Jh8pCIXVJREREZkHvwRcxMTH47LPP8NVXX+HcuXN4+eWXUVpaikmTJgEAnn/+ecyePfue9T7//HOMGjUKbdu2rTG/pKQEb731Fg4fPozLly8jISEBI0eORFBQEIYMGdLE3Wp+hbcqMWfzaQDAlH4B6NresK9iIiIiMiV6j2EZN24c8vPzMX/+fOTk5KBLly7YsWOHbiBueno65PKaOSg5ORn79+/Hr7/+es/2FAoFTp06ha+++go3b96El5cXHnnkEbz77rsGdS+WJdvOIreoAv4utoh5OETqcoiIiMyKTBAEQeoi7ldRUREcHR1RWFjYIuNZ9l3Ix4S1RyGTAete6oUefs7N/jOIiIjMjT6f37wetwHF5ZWYveEUAGBCLz+GFSIiIgkwsDTgvV/OI6uwHD7O1pj5aKjU5RAREZklBpZ6nL5aiO+OpAMAlj0eDhtlq962hoiIiP7CT+B6dPJ2wPtPhONifgl6B7lIXQ4REZHZYmCph0wmw5M9Wve2/0RERHQvtoSIiIjI4DGwEBERkcFjYCEiIiKDx8BCREREBo+BhYiIiAweAwsREREZPAYWIiIiMngMLERERGTwGFiIiIjI4DGwEBERkcFjYCEiIiKDx8BCREREBo+BhYiIiAyeSTytWRAEAEBRUZHElRAREVFjVX9uV3+O18ckAktxcTEAwMfHR+JKiIiISF/FxcVwdHSsdxmZ0JhYY+C0Wi2ysrJgb28PmUzWrNsuKiqCj48PMjIy4ODg0KzbNgSmvn+A6e8j98/4mfo+mvr+Aaa/jy21f4IgoLi4GF5eXpDL6x+lYhJnWORyOdq1a9eiP8PBwcEk/xFWM/X9A0x/H7l/xs/U99HU9w8w/X1sif1r6MxKNQ66JSIiIoPHwEJEREQGj4GlASqVCgsWLIBKpZK6lBZh6vsHmP4+cv+Mn6nvo6nvH2D6+2gI+2cSg26JiIjItPEMCxERERk8BhYiIiIyeAwsREREZPAYWIiIiMjgMbAAWL16Nfz8/GBlZYXIyEgcPXq03uV//PFHdOjQAVZWVujcuTO2b9/eSpU2jT779+WXX0Imk9WYrKysWrFa/fz222+Ijo6Gl5cXZDIZNm/e3OA6e/fuxYMPPgiVSoWgoCB8+eWXLV7n/dB3H/fu3XvPMZTJZMjJyWmdgvUUGxuLHj16wN7eHm5ubhg1ahSSk5MbXM9Y3odN2T9jeh/+61//Qnh4uO6GYr169cIvv/xS7zrGcuyq6buPxnT8avPee+9BJpNh+vTp9S7X2sfR7APLDz/8gJiYGCxYsADHjh1DREQEhgwZgry8vFqXP3jwIMaPH4/Jkyfj+PHjGDVqFEaNGoUzZ860cuWNo+/+AeKdDLOzs3XTlStXWrFi/ZSWliIiIgKrV69u1PJpaWkYPnw4Bg0ahBMnTmD69OmYMmUKdu7c2cKVNp2++1gtOTm5xnF0c3NroQrvz759+/Dqq6/i8OHD2LVrFyorK/HII4+gtLS0znWM6X3YlP0DjOd92K5dO7z33ntITEzEn3/+iYceeggjR45EUlJSrcsb07Grpu8+AsZz/O72xx9/4NNPP0V4eHi9y0lyHAUz17NnT+HVV1/Vfa/RaAQvLy8hNja21uWffPJJYfjw4TXmRUZGCi+99FKL1tlU+u7fF198ITg6OrZSdc0LgLBp06Z6l5k5c6YQFhZWY964ceOEIUOGtGBlzacx+7hnzx4BgHDjxo1Wqam55eXlCQCEffv21bmMsb0P79SY/TPm96EgCEKbNm2E//znP7W+ZszH7k717aOxHr/i4mIhODhY2LVrlzBgwADhjTfeqHNZKY6jWZ9hUavVSExMRFRUlG6eXC5HVFQUDh06VOs6hw4dqrE8AAwZMqTO5aXUlP0DgJKSEvj6+sLHx6fB3yKMjTEdv/vVpUsXeHp64uGHH8aBAwekLqfRCgsLAQDOzs51LmPMx7Ex+wcY5/tQo9Hg+++/R2lpKXr16lXrMsZ87IDG7SNgnMfv1VdfxfDhw+85PrWR4jiadWApKCiARqOBu7t7jfnu7u519vtzcnL0Wl5KTdm/0NBQrF27Flu2bMG3334LrVaL3r174+rVq61Rcour6/gVFRXh1q1bElXVvDw9PbFmzRps2LABGzZsgI+PDwYOHIhjx45JXVqDtFotpk+fjj59+qBTp051LmdM78M7NXb/jO19ePr0adjZ2UGlUmHatGnYtGkTOnbsWOuyxnrs9NlHYzt+APD999/j2LFjiI2NbdTyUhxHk3haMzWfXr161fitoXfv3njggQfw6aef4t1335WwMmqs0NBQhIaG6r7v3bs3Ll68iJUrV+Kbb76RsLKGvfrqqzhz5gz2798vdSktorH7Z2zvw9DQUJw4cQKFhYVYv349JkyYgH379tX5gW6M9NlHYzt+GRkZeOONN7Br1y6DHhxs1oHFxcUFCoUCubm5Nebn5ubCw8Oj1nU8PDz0Wl5KTdm/u1laWqJr165ITU1tiRJbXV3Hz8HBAdbW1hJV1fJ69uxp8CHgtddew88//4zffvsN7dq1q3dZY3ofVtNn/+5m6O9DpVKJoKAgAEC3bt3wxx9/YNWqVfj000/vWdYYjx2g3z7ezdCPX2JiIvLy8vDggw/q5mk0Gvz222/4+OOPUVFRAYVCUWMdKY6jWbeElEolunXrhoSEBN08rVaLhISEOnuTvXr1qrE8AOzataveXqZUmrJ/d9NoNDh9+jQ8PT1bqsxWZUzHrzmdOHHCYI+hIAh47bXXsGnTJuzevRv+/v4NrmNMx7Ep+3c3Y3sfarVaVFRU1PqaMR27+tS3j3cz9OM3ePBgnD59GidOnNBN3bt3xzPPPIMTJ07cE1YAiY5jiw3nNRLff/+9oFKphC+//FI4e/as8OKLLwpOTk5CTk6OIAiC8NxzzwmzZs3SLX/gwAHBwsJC+OCDD4Rz584JCxYsECwtLYXTp09LtQv10nf/Fi1aJOzcuVO4ePGikJiYKDz11FOClZWVkJSUJNUu1Ku4uFg4fvy4cPz4cQGAsGLFCuH48ePClStXBEEQhFmzZgnPPfecbvlLly4JNjY2wltvvSWcO3dOWL16taBQKIQdO3ZItQsN0ncfV65cKWzevFlISUkRTp8+LbzxxhuCXC4X4uPjpdqFer388suCo6OjsHfvXiE7O1s3lZWV6ZYx5vdhU/bPmN6Hs2bNEvbt2yekpaUJp06dEmbNmiXIZDLh119/FQTBuI9dNX330ZiOX13uvkrIEI6j2QcWQRCEjz76SGjfvr2gVCqFnj17CocPH9a9NmDAAGHChAk1ll+3bp0QEhIiKJVKISwsTNi2bVsrV6wfffZv+vTpumXd3d2FYcOGCceOHZOg6sapvoT37ql6nyZMmCAMGDDgnnW6dOkiKJVKISAgQPjiiy9avW596LuPy5YtEwIDAwUrKyvB2dlZGDhwoLB7925pim+E2vYNQI3jYszvw6bsnzG9D1944QXB19dXUCqVgqurqzB48GDdB7kgGPexq6bvPhrT8avL3YHFEI6jTBAEoeXO3xARERHdP7Mew0JERETGgYGFiIiIDB4DCxERERk8BhYiIiIyeAwsREREZPAYWIiIiMjgMbAQERGRwWNgISIiIoPHwEJEREQGj4GFiIiIDB4DCxERERk8BhYiIiIyeP8PEPCJAxNliMsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot them out\n",
        "m.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcJcHf7n7rId"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "Predict the results based on testing set. Upload to [Kaggle](https://www.kaggle.com/t/f072e95f51bc48978225941dba218241).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf5UTlMZ7rId",
        "outputId": "21c0a77b-b427-4687-878b-18257266fef0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 97/97 [00:09<00:00,  9.81it/s]\n"
          ]
        }
      ],
      "source": [
        "best_model.eval()\n",
        "\n",
        "total_out = []\n",
        "for text, mask in tqdm(test_data, total=len(test_data)):\n",
        "    text = text.to(device)\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    output = best_model(text, mask)\n",
        "    pred = output.logits\n",
        "    pred = torch.argmax(pred, dim=1)\n",
        "    total_out.append(pred)\n",
        "\n",
        "total_out = torch.cat(total_out).cpu().numpy().tolist()\n",
        "\n",
        "with open('pred.csv', 'w') as f:\n",
        "    f.write('index,sentiment_label\\n')\n",
        "    for i, pred in enumerate(total_out):\n",
        "        f.write('{},{}\\n'.format(i, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xWH-3RFP3MV"
      },
      "source": [
        "# Task 2: In-Context learning (32 points)\n",
        "\n",
        "In this task, you will learn how to perform sentiment classification using **prompts** without the need for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmxDdgDlP3MW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pyprind\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from transformers import BertConfig, BertTokenizer, BertForMaskedLM\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DggmfsLiP3MW"
      },
      "source": [
        "# Loading model and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I9rPa78P3MW",
        "outputId": "b2804dd4-a5aa-4cc7-f75c-da2df091cd60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "#########################################################################\n",
        "#         TODO: Design your own template(prefix) and verbalizer         #\n",
        "#########################################################################\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.examples = [\n",
        "             \"I absolutely love this! It's amazing. #positive\",\n",
        "            \"This is just okay, nothing special. #neutral\",\n",
        "            \"I'm really disappointed with this. It's terrible. #negative\"\n",
        "        ]\n",
        "        self.prefix = \"It is a [MASK] tweet.\"  #'It was [MASK] sentence' # you can modify this line\n",
        "        self.verbalizer = {\n",
        "            'positive': 0,\n",
        "            'neutral': 1,\n",
        "            'negative': 2\n",
        "        }\n",
        "\n",
        "        self.max_seq_length = 512\n",
        "        self.batch_size = 64\n",
        "\n",
        "config = Config()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "bert_type = 'bert-base-uncased'\n",
        "\n",
        "model = BertForMaskedLM.from_pretrained(bert_type, num_labels = 3)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_type)\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(bert_type)\n",
        "\n",
        "bert = model.from_pretrained(bert_type, config=bert_config).to(device)\n",
        "\n",
        "#######################################################################\n",
        "#                        End of your code                             #\n",
        "#######################################################################\n",
        "\n",
        "softmax = nn.Softmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neiRklQVP3MX"
      },
      "source": [
        "## Obtaion verbalizer ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTmt5StGP3MX"
      },
      "outputs": [],
      "source": [
        "# Utility function to obtaion verbalizer ids\n",
        "def obtain_verbalizer_ids(verbalizer, tokenizer):\n",
        "    verbalizer_ids = tokenizer.convert_tokens_to_ids(list(verbalizer.keys()))\n",
        "    index2ids = {i: verbalizer_ids[i] for i in range(len(verbalizer_ids))}\n",
        "    return verbalizer_ids, index2ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7PwfvckP3MX"
      },
      "outputs": [],
      "source": [
        "verbalizer_ids, index2ids = obtain_verbalizer_ids(config.verbalizer, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wDpPYPtP3MX"
      },
      "source": [
        "## Concatenate original text and prefix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5au4vSxP3MY"
      },
      "outputs": [],
      "source": [
        "# Utility function to concatenate prefix and text\n",
        "def concatenate_prefix(texts, config):\n",
        "    ##################################################\n",
        "    #   TODO: concatenate your own prefix and text   #\n",
        "    ##################################################\n",
        "    prefix_texts = []\n",
        "    prefix = config.prefix\n",
        "    for text in texts:\n",
        "        concatenated_text = f\"{prefix} {text}\"  # Concatenate prefix and text\n",
        "        prefix_texts.append(concatenated_text)\n",
        "    ##################################################\n",
        "    #                 End of your code               #\n",
        "    ##################################################\n",
        "    return prefix_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NXiJonZP3MY"
      },
      "outputs": [],
      "source": [
        "def load_data(config):\n",
        "    # ['texts', 'labels']\n",
        "    df = pd.read_csv('./drive/MyDrive/train.csv')\n",
        "    original_texts = df['text'].tolist()\n",
        "    labels = df['sentiment_label'].tolist()\n",
        "\n",
        "    texts = concatenate_prefix(original_texts, config)\n",
        "\n",
        "    return texts, labels\n",
        "\n",
        "\n",
        "texts, labels = load_data(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc6CT9XFP3MZ"
      },
      "outputs": [],
      "source": [
        "# Batching of texts and labels for training or processing in batches\n",
        "def pack_batch(texts, labels, batch_size):\n",
        "    \"\"\"\n",
        "    :param texts: list\n",
        "    :param labels: list\n",
        "    :param batch_size: int\n",
        "    :return batch_X: list\n",
        "            [[text11, text12, ...], [text21, text22, ...], ...]\n",
        "    :return batch_y: list\n",
        "            [[label11, label12, ...], [label21, label22, ...], ...]\n",
        "    :return batch_count: int\n",
        "    \"\"\"\n",
        "    assert len(texts) == len(labels)\n",
        "\n",
        "    if len(texts) % batch_size != 0:\n",
        "        flag = False\n",
        "        batch_count = int(len(texts) / batch_size) + 1\n",
        "    else:\n",
        "        flag = True\n",
        "        batch_count = int(len(texts) / batch_size)\n",
        "\n",
        "    batch_X, batch_y = [], []\n",
        "\n",
        "    if flag:\n",
        "        for i in range(batch_count):\n",
        "            batch_X.append(texts[i * batch_size: (i + 1) * batch_size])\n",
        "            batch_y.append(labels[i * batch_size: (i + 1) * batch_size])\n",
        "    else:\n",
        "        for i in range(batch_count):\n",
        "            if i == batch_count - 1:\n",
        "                batch_X.append(texts[i * batch_size:])\n",
        "                batch_y.append(labels[i * batch_size:])\n",
        "            else:\n",
        "                batch_X.append(texts[i * batch_size: (i + 1) * batch_size])\n",
        "                batch_y.append(labels[i * batch_size: (i + 1) * batch_size])\n",
        "\n",
        "    return batch_X, batch_y, batch_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaniAvO-P3MZ"
      },
      "outputs": [],
      "source": [
        "batch_X, batch_y, batch_count = pack_batch(texts, labels, config.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0sksq1MP3MZ"
      },
      "source": [
        "## Inferencing the model without training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szbzk7JwP3MZ",
        "outputId": "bff303b1-27b2-4f99-d392-dca03080d55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[100 %] Time elapsed: 00:07:06 | ETA: 00:00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.519028 | precision: 0.375959 | recall: 0.519028 | f1: 0.435912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Total time elapsed: 00:07:06\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    predict_all = np.array([], dtype=int)\n",
        "    labels_all = np.array([], dtype=int)\n",
        "    pper = pyprind.ProgPercent(batch_count) #此行使用 pyprind 函式庫初始化進度條來追蹤迴圈的進度\n",
        "    for i in range(batch_count):\n",
        "        inputs = batch_X[i]\n",
        "        labels = batch_y[i]\n",
        "\n",
        "        # Using the BERT tokenizer (tokenizer.batch_encode_plus), adding special tokens, ensuring a maximum sequence length, and handling padding/truncation\n",
        "        #原始文本轉換成 BERT 相容的輸入格式-轉換成BERT可理解形式。此步驟透過標記化、添加特殊標記以及處理填充/截斷以適合指定的最大序列長度 (config.max_seq_length) 來準備 BERT 的輸入資料。\n",
        "        tokens = tokenizer.batch_encode_plus(inputs, add_special_tokens=True,\n",
        "                                             max_length=config.max_seq_length,\n",
        "                                             padding='max_length', truncation=True)\n",
        "\n",
        "        ids = torch.tensor(tokens['input_ids']).to(device)\n",
        "        attention_mask = torch.tensor(tokens['attention_mask']).to(device)\n",
        "\n",
        "        # Shape: (batch_size, max_seq_length, vocab_size)\n",
        "        logits = bert(ids, attention_mask=attention_mask).logits\n",
        "\n",
        "        mask_token_index = (ids == tokenizer.mask_token_id).nonzero(as_tuple=True)\n",
        "\n",
        "        # Find [MASK] logits\n",
        "        # shape: (batch_size, vocab_size)\n",
        "        masked_logits = logits[mask_token_index[0], mask_token_index[1], :]\n",
        "\n",
        "        # Extract the logits of the word in the verbalizer at the [MASK] position\n",
        "        # shape: (batch_size, verbalizer_size)\n",
        "        verbalizer_logits = masked_logits[:, verbalizer_ids]\n",
        "\n",
        "        # Construct a pseudo-distribution from the logits in these verbalizers\n",
        "        pseudo_distribution = softmax(verbalizer_logits)\n",
        "\n",
        "        #################################################################################\n",
        "        #   1. Find the index with the maximum probability in the pseudo-distribution   #\n",
        "        #   2. Convert the index to the corresponding word ID                           #\n",
        "        #   3. Convert the ID to a token                                                #\n",
        "        #   4. Find the label corresponding to the token                                #\n",
        "        #################################################################################\n",
        "\n",
        "        pred_indices = pseudo_distribution.argmax(dim=-1)\n",
        "\n",
        "        pred_ids = [verbalizer_ids[idx.item()] for idx in pred_indices]\n",
        "\n",
        "        pred_tokens = tokenizer.convert_ids_to_tokens(pred_ids)\n",
        "\n",
        "        pred_labels =  [config.verbalizer[token] for token in pred_tokens]\n",
        "\n",
        "        #################################################################################\n",
        "        #                             End of your code                                  #\n",
        "        #################################################################################\n",
        "\n",
        "        predict_all = np.append(predict_all, pred_labels)\n",
        "        labels_all = np.append(labels_all, labels)\n",
        "\n",
        "        pper.update()\n",
        "\n",
        "    acc = accuracy_score(labels_all, predict_all)\n",
        "    p = precision_score(labels_all, predict_all, average=\"weighted\")\n",
        "    r = recall_score(labels_all, predict_all, average=\"weighted\")\n",
        "    f1 = f1_score(labels_all, predict_all, average=\"weighted\")\n",
        "\n",
        "    print('accuracy: %f | precision: %f | recall: %f | f1: %f' % (acc, p, r, f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al7jw8USP3MZ"
      },
      "source": [
        "# Task 3: LM-BFF (45 points)\n",
        "\n",
        "https://arxiv.org/pdf/2012.15723.pdf\n",
        "\n",
        "Unlike the previous task, LM-BFF can generate templates and verbalizers automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdHL2lvxP3Ma"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0Ab4cAoP3Ma"
      },
      "source": [
        "請先到共用雲端硬碟將檔案 `SST-2.zip`，建立捷徑到自己的雲端硬碟中。\n",
        "\n",
        "> 操作步驟\n",
        "1. 點開雲端[連結](https://drive.google.com/file/d/14MDYFasXU94dUE9DjgfcZE61iTRI2007/view?usp=sharing)\n",
        "2. 點選右上角「新增雲端硬碟捷徑」\n",
        "3. 點選「我的雲端硬碟」\n",
        "4. 點選「新增捷徑」\n",
        "\n",
        "完成以上流程會在你的雲端硬碟中建立一個檔案的捷徑，接著我們在colab中取得權限即可使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYBGFEmlP3Ma"
      },
      "source": [
        "# Install openprompt\n",
        "\n",
        "This library provides a standard, flexible and extensible framework to deploy the prompt-learning pipeline.\n",
        "\n",
        "[OpenPrompt Documentation](https://thunlp.github.io/OpenPrompt/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3l02R3RP3Ma"
      },
      "outputs": [],
      "source": [
        "!pip install openprompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1Je4ddjP3Ma"
      },
      "source": [
        "# Import openprompt package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK9M0vd6P3Ma"
      },
      "outputs": [],
      "source": [
        "from openprompt.plms import load_plm\n",
        "from openprompt.prompts.prompt_generator import T5TemplateGenerator\n",
        "from openprompt.pipeline_base import PromptDataLoader, PromptForClassification\n",
        "from openprompt.prompts import ManualTemplate\n",
        "from openprompt.trainer import ClassificationRunner\n",
        "import copy\n",
        "import torch\n",
        "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CefOKyLP3Ma"
      },
      "source": [
        "# Setup cuda and whether to perform automatic generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ_4_bkxP3Ma"
      },
      "outputs": [],
      "source": [
        "cuda = True\n",
        "auto_t = True # Whether to perform automatic template generation\n",
        "auto_v = True # Whether to perform automatic verbalizer generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doZyzT7VP3Ma"
      },
      "source": [
        "# Load dataset and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fca7QbMrP3Mb"
      },
      "outputs": [],
      "source": [
        "from openprompt.data_utils.text_classification_dataset import SST2Processor\n",
        "dataset = {}\n",
        "dataset['train'] = SST2Processor().get_train_examples(\"/SST-2/\")\n",
        "dataset['validation'] = SST2Processor().get_dev_examples(\"/SST-2/\")\n",
        "dataset['test'] = SST2Processor().get_test_examples(\"/SST-2/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ivD9hvNP3Mb"
      },
      "outputs": [],
      "source": [
        "#print('load model...')\n",
        "from openprompt.plms import load_plm\n",
        "\n",
        "# load mlm model for main tasks\n",
        "plm, tokenizer, model_config, WrapperClass = load_plm(\"roberta\", \"roberta-large\")\n",
        "\n",
        "# load generation model for template generation\n",
        "template_generate_model, template_generate_tokenizer, template_generate_model_config, template_tokenizer_wrapper = load_plm('t5', 't5-large')\n",
        "\n",
        "from openprompt.prompts import ManualVerbalizer, ManualTemplate\n",
        "\n",
        "# if you wish to do automatic label word generation, the verbalizer is not the final verbalizer, and is only used for template generation.\n",
        "verbalizer = ManualVerbalizer(tokenizer=tokenizer, num_classes=2, label_words=[['terrible'],['great']]) # Manually generate the verbalizer\n",
        "\n",
        "\n",
        "###################################################################################################################\n",
        "#   TODO: You need to switch LMBFFTemplateGenerationTemplate or ManualTemplate to                                 #\n",
        "#         compare auto generate template and manual generate template                                             #\n",
        "###################################################################################################################\n",
        "from openprompt.prompts.prompt_generator import LMBFFTemplateGenerationTemplate\n",
        "\n",
        "############################################\n",
        "#   LMBFFTemplateGenerationTemplate        #\n",
        "############################################\n",
        "import random\n",
        "\n",
        "# number of demonstrations\n",
        "num_demonstrations = 1  # try different number\n",
        "\n",
        "demonstrations = []\n",
        "\n",
        "for _ in range(num_demonstrations):\n",
        "    # random choice training set example with label 0\n",
        "    random_example_1 = random.choice([example for example in dataset['train'] if example.label == 0])\n",
        "\n",
        "    # random choice training set example with label 1\n",
        "    random_example_2 = random.choice([example for example in dataset['train'] if example.label == 1])\n",
        "\n",
        "    demonstration = f'{random_example_1.text_a} It was terrible. {random_example_2.text_a} It was great.'\n",
        "    demonstrations.append(demonstration)\n",
        "\n",
        "# You can modify the demonstrations and try different combinations\n",
        "template_text = '{\"placeholder\": \"text_a\"} {\"mask\"} {\"meta\": \"labelword\"} {\"mask\"}.' + ' '.join(demonstrations)\n",
        "template = LMBFFTemplateGenerationTemplate(tokenizer=template_generate_tokenizer, verbalizer=verbalizer, text=template_text)\n",
        "\n",
        "#############################################\n",
        "#   End of LMBFFTemplateGenerationTemplate  #\n",
        "#############################################\n",
        "\n",
        "########################################\n",
        "#          ManualTemplate              #\n",
        "########################################\n",
        "\n",
        "#template = ManualTemplate(tokenizer=tokenizer, text='{\"placeholder\":\"text_a\"} It was {\"mask\"}.')\n",
        "\n",
        "########################################\n",
        "#          End of ManualTemplate       #\n",
        "########################################\n",
        "\n",
        "###################################################################################################################\n",
        "#                                           End of your code                                                      #\n",
        "###################################################################################################################\n",
        "\n",
        "\n",
        "# view wrapped example\n",
        "wrapped_example = template.wrap_one_example(dataset['train'][0])\n",
        "print(\"dataset:\", dataset['train'][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKB1w3ZpP3Mb"
      },
      "source": [
        "# Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy2Qj1smP3Mb"
      },
      "outputs": [],
      "source": [
        "from openprompt.plms import load_plm\n",
        "from openprompt.prompts.prompt_generator import T5TemplateGenerator\n",
        "from openprompt.pipeline_base import PromptDataLoader, PromptForClassification\n",
        "from openprompt.prompts import ManualTemplate\n",
        "from openprompt.trainer import ClassificationRunner\n",
        "import copy\n",
        "import torch\n",
        "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "\n",
        "# Returns the best evaluation score achieved during training\n",
        "def fit(model, train_dataloader, val_dataloader, loss_func, optimizer):\n",
        "    best_score = 0.0\n",
        "    for epoch in range(5):\n",
        "        train_loss = train_epoch(model, train_dataloader, loss_func, optimizer)\n",
        "        score = evaluate(model, val_dataloader)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "        print(f\"Epoch {epoch+1}: Train loss={train_loss}, Eval score={score}\")\n",
        "    return best_score\n",
        "\n",
        "# Trains the model on the training data and computes the training loss\n",
        "def train_epoch(model, train_dataloader, loss_func, optimizer):\n",
        "    model.train()\n",
        "    loss_all = []\n",
        "    for step, inputs in enumerate(train_dataloader):\n",
        "        if cuda:\n",
        "            inputs = inputs.cuda()\n",
        "        #####################################################\n",
        "        # 1. Put correct variables into model to get logits #\n",
        "        # 2. Get labels                                     #\n",
        "        # 3. Evalutate using loss_func                         #\n",
        "        # 4. Append loss to loss_all                        #\n",
        "        #####################################################\n",
        "        logits = ...\n",
        "        labels = ...\n",
        "        loss = ...\n",
        "        loss.backward()\n",
        "        loss_all.append(...)\n",
        "        #####################################################\n",
        "        #                 End of your code                  #\n",
        "        #####################################################\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return np.mean(loss_all)\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    alllabels = []\n",
        "    with torch.no_grad():\n",
        "        for step, inputs in enumerate(val_dataloader):\n",
        "            if cuda:\n",
        "                inputs = inputs.cuda()\n",
        "            #####################################################\n",
        "            # 1. Put correct variables into model to get logits #\n",
        "            # 2. Get labels                                     #\n",
        "            # 3. Extend labels to list                          #\n",
        "            # 4. Get predictions and extend preds to list        #\n",
        "            #####################################################\n",
        "            logits = ...\n",
        "            labels = ...\n",
        "            alllabels.extend(...)\n",
        "            allpreds.extend(...)\n",
        "            #####################################################\n",
        "            #                 End of your code                  #\n",
        "            #####################################################\n",
        "    acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D7WtKhjP3Mb"
      },
      "source": [
        "# Automatic template generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9t9ysfIP3Mb"
      },
      "source": [
        "Generated template from TemplateGenerator and find the best template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41uDn9ROP3Mb"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "class ManualTemplateWithoutParse(ManualTemplate):\n",
        "    \"\"\"The generated template from TemplateGenerator is a list of dict of parsed template_text. So no further parsing is needed.\"\"\"\n",
        "    def on_text_set(self):\n",
        "        pass\n",
        "\n",
        "# Template generation\n",
        "if auto_t:\n",
        "    print('performing auto_t...')\n",
        "\n",
        "    if cuda:\n",
        "        template_generate_model = template_generate_model.cuda()\n",
        "\n",
        "    # Creates an instance of T5TemplateGenerator, used for generating text templates\n",
        "    template_generator = T5TemplateGenerator(template_generate_model, template_generate_tokenizer, template_tokenizer_wrapper, verbalizer, beam_width=5) # Beam_width is set to 5 here for efficiency; to improve performance, try a larger number.\n",
        "\n",
        "\n",
        "    dataloader = PromptDataLoader(dataset['train'], template, tokenizer=template_generate_tokenizer, tokenizer_wrapper_class=template_tokenizer_wrapper, batch_size=len(dataset['train']), decoder_max_length=128, max_seq_length=128, shuffle=False, teacher_forcing=False) # Register all data at once\n",
        "    for data in dataloader:\n",
        "        if cuda:\n",
        "            data = data.cuda()\n",
        "        template_generator._register_buffer(data)\n",
        "\n",
        "    template_generate_model.eval()\n",
        "    print('generating...')\n",
        "    template_texts = template_generator._get_templates() # Calls _get_templates on template_generator to generate template texts.\n",
        "\n",
        "    # Converting and Printing Templates\n",
        "    original_template = template.text\n",
        "    template_texts = [template_generator.convert_template(template_text, original_template) for template_text in template_texts]\n",
        "    # template_generator._show_template()\n",
        "    template_generator.release_memory()\n",
        "    # Generate a number of candidate template text\n",
        "    print(template_texts)\n",
        "\n",
        "    # Iterate over each candidate and select the best one\n",
        "    best_metrics = 0.0\n",
        "    best_template_text = None\n",
        "    for template_text in tqdm(template_texts):\n",
        "        verbalizer = ManualVerbalizer(tokenizer=tokenizer, num_classes=2, label_words=[['terrible'],['great']])\n",
        "        template = LMBFFTemplateGenerationTemplate(tokenizer=template_generate_tokenizer, verbalizer=verbalizer, text=template_text)\n",
        "        print(f\"current template: {template_text}, wrapped example: {template.wrap_one_example(dataset['train'][0])}\")\n",
        "\n",
        "        train_dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, shuffle=True)\n",
        "        valid_dataloader = PromptDataLoader(dataset['validation'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
        "\n",
        "        model = PromptForClassification(copy.deepcopy(plm), template, verbalizer)\n",
        "\n",
        "        loss_func = torch.nn.CrossEntropyLoss()\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "        # it's always good practice to set no decay to bias and LayerNorm parameters\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "        if cuda:\n",
        "            model = model.cuda()\n",
        "        score = fit(model, train_dataloader, valid_dataloader, loss_func, optimizer)\n",
        "\n",
        "        #######################################################\n",
        "        # TODO: Use score to Find your best template_text     #\n",
        "        #######################################################\n",
        "        ...\n",
        "        #######################################################\n",
        "        #                 End of your code                    #\n",
        "        #######################################################\n",
        "    # Use the best template\n",
        "    verbalizer = ManualVerbalizer(tokenizer=tokenizer, num_classes=2, label_words=[['terrible'],['great']])\n",
        "    template = LMBFFTemplateGenerationTemplate(tokenizer=template_generate_tokenizer, verbalizer=verbalizer, text=template_text)\n",
        "    print(\"final best template:\", best_template_text)\n",
        "    print(\"wrapped example:\", template.wrap_one_example(dataset[\"train\"][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRxvcgCjP3Mc"
      },
      "source": [
        "# Automatic erbalizer generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPmMlc6EP3Mc"
      },
      "source": [
        "Verbalizer template from VerbalizerGenerator and find the best verbalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZhG4gMYP3Mc"
      },
      "outputs": [],
      "source": [
        "# Verbalizer generation\n",
        "from openprompt.prompts.prompt_generator import RobertaVerbalizerGenerator\n",
        "if auto_v:\n",
        "    print('performing auto_v...')\n",
        "    # Load generation model for verbalizer generation\n",
        "    if cuda:\n",
        "        plm = plm.cuda()\n",
        "\n",
        "    # Creates an instance of RobertaVerbalizerGenerator, used for generating verbalizer.\n",
        "    verbalizer_generator = RobertaVerbalizerGenerator(model=plm, tokenizer=tokenizer, candidate_num=20, label_word_num_per_class=20) # To improve performance, try larger numbers\n",
        "\n",
        "\n",
        "    dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, batch_size=32)\n",
        "    for data in dataloader:\n",
        "        if cuda:\n",
        "            data = data.cuda()\n",
        "        verbalizer_generator.register_buffer(data)\n",
        "\n",
        "    # Calls generate on verbalizer_generator to generate label words.\n",
        "    label_words_list = verbalizer_generator.generate()\n",
        "    verbalizer_generator.release_memory()\n",
        "\n",
        "    # Iterate over each candidate and select the best one\n",
        "    current_verbalizer = copy.deepcopy(verbalizer)\n",
        "    best_metrics = 0.0\n",
        "    best_label_words = None\n",
        "    for label_words in tqdm(label_words_list):\n",
        "        current_verbalizer.label_words = label_words\n",
        "        train_dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, shuffle=True)\n",
        "        valid_dataloader = PromptDataLoader(dataset['validation'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
        "\n",
        "        model = PromptForClassification(copy.deepcopy(plm), template, current_verbalizer)\n",
        "\n",
        "        loss_func = torch.nn.CrossEntropyLoss()\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "        # it's always good practice to set no decay to bias and LayerNorm parameters\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "        if cuda:\n",
        "            model = model.cuda()\n",
        "        score = fit(model, train_dataloader, valid_dataloader, loss_func, optimizer)\n",
        "\n",
        "        #######################################################\n",
        "        # TODO: Use score to find your best_label_word        #\n",
        "        #######################################################\n",
        "        ...\n",
        "        #######################################################\n",
        "        #                 End of your code                    #\n",
        "        #######################################################\n",
        "    # use the best verbalizer\n",
        "    print(\"final best label words:\", best_label_words)\n",
        "    verbalizer = ManualVerbalizer(tokenizer, num_classes=2, label_words=best_label_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1VgZUOzP3Mc"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHFR3ofZP3Mc"
      },
      "outputs": [],
      "source": [
        "train_dataloader = PromptDataLoader(dataset['train'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass, shuffle=True)\n",
        "valid_dataloader = PromptDataLoader(dataset['validation'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
        "test_dataloader = PromptDataLoader(dataset['test'], template, tokenizer=tokenizer, tokenizer_wrapper_class=WrapperClass)\n",
        "\n",
        "\n",
        "model = PromptForClassification(copy.deepcopy(plm), template, verbalizer)\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "# It's always good practice to set no decay to bias and LayerNorm parameters\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "score = fit(model, train_dataloader, valid_dataloader, loss_func, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrgQzG9xP3Mc"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "Predict the results based on testing set. Upload to [Kaggle](https://www.kaggle.com/t/5b8876ed26fd495b8353ad7ce94b6f65)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzmwkBhKP3Md"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "allpreds = []\n",
        "for step, inputs in enumerate(test_dataloader):\n",
        "    if cuda:\n",
        "        inputs = inputs.cuda()\n",
        "    logits = model(inputs)\n",
        "    allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "with open('pred.csv', 'w') as f:\n",
        "    f.write('index,sentiment_label\\n')\n",
        "    for i, pred in enumerate(allpreds):\n",
        "        f.write('{},{}\\n'.format(i, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-6OJDsJP3Md"
      },
      "source": [
        "# Report (15 points)\n",
        "\n",
        "- Task 1: Compare **two** different models you employed and provide a brief discussion of your implementation.\n",
        "\n",
        "- Task 2: You need to try at least **three** different templates and verbalizers to compare how your prompts work with the model. Report your performance in zero-shot, one-shot, and few-shot scenarios, with examples drawn from the training set.\n",
        "\n",
        "- Task 3: Try at least three different manually crafted templates to compare them with auto-generated templates. Evaluate the performance with different numbers of demonstrations and plot the graph from Figure 3 in the paper (https://arxiv.org/pdf/2012.15723.pdf). Also, report your best template and verbalizer.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "51ee1b965d6f75a20b2b6babb72920dce4fab5775c12eb1659af0fb55d185fed"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}